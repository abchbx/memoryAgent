# -*- coding: utf-8 -*-
# -----------------------------------------------------------------------------
# æ­¥éª¤ 1: å¯¼å…¥æ‰€æœ‰å¿…è¦çš„åº“
# -----------------------------------------------------------------------------
import os
import json
import logging
import time
import datetime
import streamlit as st
from openai import OpenAI
from dotenv import load_dotenv
import chromadb
from chromadb.utils import embedding_functions

# -----------------------------------------------------------------------------
# æ­¥éª¤ 2: åç«¯é€»è¾‘ä»£ç  (V3.1 - ç¼“å­˜ä¿®å¤ç‰ˆ)
# -----------------------------------------------------------------------------

# --- æ—¥å¿—è®°å½•é…ç½® ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# --- æ ¸å¿ƒé…ç½®ç±» ---
class Config:
    """é›†ä¸­ç®¡ç†æ‰€æœ‰é…ç½®"""
    load_dotenv()
    ZHIPU_BASE_URL = "https://open.bigmodel.cn/api/paas/v4/"
    LLM_MODEL = "glm-4-flash"
    EMBEDDING_MODEL = "BAAI/bge-base-zh-v1.5"
    DB_PATH = "/workspace/memoryAgent/user_centric_db_v3"
    CHAT_COLLECTION_NAME = "user_chat_history"
    FACT_MEMORY_COLLECTION_NAME = "user_fact_memory" # V3.0: åå­—å˜æ›´ï¼Œæ›´æ¸…æ™°
    EVENT_MEMORY_COLLECTION_NAME = "user_event_memory" # V3.0: æ–°å¢äº‹ä»¶è®°å¿†é›†åˆ
    RAG_COLLECTION_NAME = "user_rag_documents"

    # V3.0: System-Prompt å‡çº§ï¼Œå¢åŠ äº†äº‹ä»¶è®°å¿†æ¨¡å—
    SYSTEM_PROMPT_TEMPLATE = """
    ä½ æ˜¯ä¸ºç”¨æˆ· {user_id} æœåŠ¡çš„é¡¶çº§ä¸ªäººæ™ºèƒ½åŠ©æ‰‹ï¼Œæ‹¥æœ‰å“è¶Šçš„è®°å¿†ã€æ¨ç†å’ŒçŸ¥è¯†åº“æŸ¥è¯¢èƒ½åŠ›ã€‚

    # å…³äºç”¨æˆ· {user_id} çš„å·²çŸ¥äº‹å® (ä½ çš„é™æ€è®°å¿†):
    {long_term_memory}

    # å…³äºç”¨æˆ· {user_id} çš„ç›¸å…³äº‹ä»¶ä¸è®¡åˆ’ (ä½ çš„åŠ¨æ€è®°å¿†):
    {event_memory}

    # ä½ çš„å·¥ä½œæµç¨‹:
    1.  **æ·±å…¥ç†è§£**: åˆ†æç”¨æˆ·çš„æœ€æ–°é—®é¢˜ã€‚
    2.  **ç»“åˆè®°å¿†ä¸çŸ¥è¯†**: æˆ‘ä¼šä¸ºä½ æä¾›ä¸‰ç±»ä¿¡æ¯ï¼šç”¨æˆ·çš„é•¿æœŸè®°å¿†(äº‹å®å’Œäº‹ä»¶)ã€ç›¸å…³çš„å†å²å¯¹è¯ã€ä»¥åŠä»ç”¨æˆ·ä¸Šä¼ çš„çŸ¥è¯†åº“ä¸­æ£€ç´¢åˆ°çš„ç›¸å…³èµ„æ–™ã€‚ä½ å¿…é¡»å°†è¿™ä¸‰è€…ç»“åˆèµ·æ¥ï¼Œå½¢æˆå¯¹ä¸Šä¸‹æ–‡çš„å®Œæ•´ç†è§£ã€‚
    3.  **ä¼˜å…ˆä½¿ç”¨çŸ¥è¯†åº“**: å¦‚æœçŸ¥è¯†åº“ä¸­æä¾›äº†ä¸é—®é¢˜ç›´æ¥ç›¸å…³çš„ä¿¡æ¯ï¼Œè¯·ä¼˜å…ˆåŸºäºè¿™äº›ä¿¡æ¯è¿›è¡Œå›ç­”ï¼Œå› ä¸ºå®ƒä»¬æ˜¯ç”¨æˆ·æŒ‡å®šçš„æƒå¨èµ„æ–™ã€‚
    4.  **ä¸ªæ€§åŒ–å›ç­”**: åŸºäºæ‰€æœ‰ä¿¡æ¯ï¼Œä¸ºç”¨æˆ· {user_id} ç”Ÿæˆä¸€ä¸ªå¯Œæœ‰æ´å¯ŸåŠ›ã€è¿è´¯ä¸”ä¸ªæ€§åŒ–çš„å›ç­”ã€‚
    """
    
    MEMORY_EXTRACTION_INTERVAL = 4

# --- æ–‡æœ¬åˆ†å‰²å™¨ ---
def simple_text_splitter(text: str, max_chunk_size: int = 500) -> list[str]:
    """ä¸€ä¸ªç®€å•çš„æ–‡æœ¬åˆ†å‰²å™¨ï¼ŒæŒ‰å¥å­åˆ†å‰²"""
    sentences = text.replace("\n", " ").replace("\r", " ").split('ã€‚')
    chunks, current_chunk = [], ""
    for sentence in sentences:
        if not sentence.strip(): continue
        sentence += "ã€‚"
        if len(current_chunk) + len(sentence) <= max_chunk_size:
            current_chunk += sentence
        else:
            chunks.append(current_chunk.strip())
            current_chunk = sentence
    if current_chunk: chunks.append(current_chunk.strip())
    return chunks

# --- æ•°æ®åº“ç®¡ç†ç±» ---
class ChatHistoryDB:
    def __init__(self, config: Config):
        self.config = config
        try:
            os.makedirs(config.DB_PATH, exist_ok=True)
            self.db_client = chromadb.PersistentClient(path=self.config.DB_PATH)
            self.embedding_func = embedding_functions.SentenceTransformerEmbeddingFunction(
                model_name=self.config.EMBEDDING_MODEL
            )
            self.chat_collection = self.db_client.get_or_create_collection(name=self.config.CHAT_COLLECTION_NAME, embedding_function=self.embedding_func)
            self.fact_memory_collection = self.db_client.get_or_create_collection(name=self.config.FACT_MEMORY_COLLECTION_NAME, embedding_function=self.embedding_func)
            self.event_memory_collection = self.db_client.get_or_create_collection(name=self.config.EVENT_MEMORY_COLLECTION_NAME, embedding_function=self.embedding_func) # V3.0: åˆå§‹åŒ–äº‹ä»¶é›†åˆ
            self.rag_collection = self.db_client.get_or_create_collection(name=self.config.RAG_COLLECTION_NAME, embedding_function=self.embedding_func)
            logging.info(f"æ•°æ®åº“åˆå§‹åŒ–æˆåŠŸ: {config.DB_PATH}")
        except Exception as e:
            logging.error(f"åˆå§‹åŒ– ChromaDB å¤±è´¥: {e}")
            st.error(f"æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")
            raise

    def add_document_to_rag(self, user_id: str, file_name: str, file_content: str, progress_callback=None):
        if progress_callback: progress_callback(0, "æ­¥éª¤ 1/2: æ­£åœ¨åˆ†å‰²æ–‡ä»¶...")
        chunks = simple_text_splitter(file_content)
        if not chunks:
            if progress_callback: progress_callback(100, "æ–‡ä»¶å†…å®¹ä¸ºç©ºï¼Œå·²è·³è¿‡ã€‚")
            return

        total_chunks = len(chunks)
        logging.info(f"æ–‡ä»¶ '{file_name}' è¢«åˆ†å‰²æˆ {total_chunks} ä¸ªç‰‡æ®µã€‚")
        if progress_callback: progress_callback(5, f"æ­¥éª¤ 2/2: åˆ†å‰²å®Œæˆï¼Œå‡†å¤‡è®¡ç®—å‘é‡... (å…± {total_chunks} å—)")
        
        batch_size = 32
        for i in range(0, total_chunks, batch_size):
            batch_chunks = chunks[i:i + batch_size]
            batch_ids = [f"rag_{user_id}_{file_name}_{time.time()}_{i+j}" for j in range(len(batch_chunks))]
            batch_metadatas = [{"user_id": user_id, "source": file_name} for _ in batch_chunks]
            
            self.rag_collection.add(ids=batch_ids, documents=batch_chunks, metadatas=batch_metadatas)
            
            if progress_callback:
                processed_count = i + len(batch_chunks)
                percentage = min(int((processed_count / total_chunks) * 100), 100)
                status_text = f"æ­¥éª¤ 2/2: æ­£åœ¨è®¡ç®—å‘é‡... ({processed_count}/{total_chunks})"
                progress_callback(percentage, status_text)
        
        if progress_callback: progress_callback(100, "çŸ¥è¯†åº“å­¦ä¹ å®Œæˆï¼")
        logging.info(f"æ–‡ä»¶ '{file_name}' å·²æˆåŠŸæ·»åŠ è‡³çŸ¥è¯†åº“ã€‚")

    def save_message(self, user_id: str, message: dict):
        if not all(k in message for k in ['role', 'content']) or not message.get('content'): return
        timestamp = time.time()
        doc_id = f"msg_{user_id}_{timestamp}"
        self.chat_collection.add(ids=[doc_id], documents=[message['content']], metadatas=[{"user_id": user_id, "role": message['role'], "timestamp": timestamp}])

    def load_history_by_user(self, user_id: str) -> list:
        if not user_id: return []
        results = self.chat_collection.get(where={"user_id": user_id})
        if not results['ids']: return []
        packaged_messages = sorted([{"doc": results['documents'][i], "meta": results['metadatas'][i]} for i in range(len(results['ids']))], key=lambda m: m['meta']['timestamp'])
        return [{"role": msg['meta']['role'], "content": msg['doc']} for msg in packaged_messages]

    def clear_user_chat_history(self, user_id: str):
        if self.chat_collection.get(where={"user_id": user_id})['ids']:
            self.chat_collection.delete(where={"user_id": user_id})
            logging.info(f"å·²æ¸…ç©ºç”¨æˆ· {user_id} çš„å¯¹è¯å†å²ã€‚")
            
    # V3.0: é‡æ„æ­¤å‡½æ•°ä»¥åŒæ—¶å¤„ç†äº‹å®å’Œäº‹ä»¶
    def save_structured_memory(self, user_id: str, memory_data: dict):
        """ä¿å­˜ç»“æ„åŒ–çš„è®°å¿†ï¼ŒåŒ…æ‹¬é™æ€äº‹å®å’ŒåŠ¨æ€äº‹ä»¶"""
        # 1. ä¿å­˜é™æ€äº‹å®
        facts = memory_data.get('static_facts', {})
        if facts and isinstance(facts, dict):
            logging.info(f"æ­£åœ¨ä¸ºç”¨æˆ· {user_id} ä¿å­˜æˆ–æ›´æ–° {len(facts)} æ¡äº‹å®è®°å¿†...")
            items_to_save = []
            for key, value in facts.items():
                if isinstance(value, dict):
                    for sub_key, sub_value in value.items():
                        items_to_save.append((f"{key}_{sub_key}", sub_value))
                else:
                    items_to_save.append((key, value))
            
            for key, value in items_to_save:
                doc_id = f"fact_{user_id}_{key}"
                self.fact_memory_collection.upsert(
                    ids=[doc_id],
                    documents=[f"ç”¨æˆ·çš„ä¸ªäººä¿¡æ¯ï¼š{key} æ˜¯ {value}ã€‚"],
                    metadatas=[{"user_id": user_id, "key": key, "timestamp": time.time()}]
                )

        # 2. ä¿å­˜åŠ¨æ€äº‹ä»¶
        events = memory_data.get('events', [])
        if events and isinstance(events, list):
            logging.info(f"æ­£åœ¨ä¸ºç”¨æˆ· {user_id} ä¿å­˜ {len(events)} æ¡äº‹ä»¶è®°å¿†...")
            for event in events:
                if isinstance(event, dict) and 'description' in event:
                    description = event['description']
                    event_time_str = event.get('event_time', 'æœªçŸ¥æ—¶é—´')
                    doc_id = f"event_{user_id}_{time.time()}"
                    self.event_memory_collection.add(
                        ids=[doc_id],
                        documents=[f"äº‹ä»¶ï¼š{description}ï¼Œå‘ç”Ÿæ—¶é—´ï¼š{event_time_str}"],
                        metadatas={"user_id": user_id, "event_time": event_time_str, "saved_at": time.time()}
                    )

    def load_fact_memory(self, user_id: str, top_k: int = 20) -> str:
        """åŠ è½½é™æ€äº‹å®è®°å¿†"""
        results = self.fact_memory_collection.get(where={"user_id": user_id}, limit=top_k)
        return "\n".join(f"- {doc}" for doc in results.get('documents', [])) or "æš‚æ— "
    
    # V3.0: æ–°å¢å‡½æ•°ï¼Œç”¨äºåŠ è½½å’Œæ™ºèƒ½ç­›é€‰äº‹ä»¶è®°å¿†
    def load_event_memory(self, user_id: str, query: str = None, top_k_similar: int = 3, past_k_recent: int = 5) -> str:
        """åŠ è½½ä¸ç”¨æˆ·ç›¸å…³çš„äº‹ä»¶è®°å¿†ï¼ŒåŒ…æ‹¬æœªæ¥çš„ã€æœ€è¿‘å‘ç”Ÿçš„å’Œä¸æŸ¥è¯¢ç›¸å…³çš„"""
        if not user_id: return "æš‚æ— "
        
        all_events = self.event_memory_collection.get(where={"user_id": user_id})
        if not all_events['ids']: return "æš‚æ— "

        # ç®€å•çš„æœªæ¥äº‹ä»¶è¯†åˆ« (å®é™…åº”ç”¨ä¸­å¯èƒ½éœ€è¦æ›´å¤æ‚çš„æ—¥æœŸè§£æ)
        future_events = [doc for doc in all_events['documents'] if any(kw in doc for kw in ["æ˜å¤©", "ä¸‹å‘¨", "å°†è¦", "è®¡åˆ’"])]
        
        # è·å–æœ€è¿‘å‘ç”Ÿçš„äº‹ä»¶
        sorted_events = sorted(zip(all_events['documents'], all_events['metadatas']), key=lambda x: x[1]['saved_at'], reverse=True)
        recent_past_events = [doc for doc, meta in sorted_events[:past_k_recent]]

        # è·å–ä¸å½“å‰æŸ¥è¯¢æœ€ç›¸å…³çš„äº‹ä»¶
        similar_events = []
        if query:
            query_results = self.event_memory_collection.query(query_texts=[query], where={"user_id": user_id}, n_results=top_k_similar)
            similar_events = query_results.get("documents", [[]])[0]

        # åˆå¹¶å¹¶å»é‡
        final_events = []
        for event_list in [future_events, recent_past_events, similar_events]:
            for event in event_list:
                if event not in final_events:
                    final_events.append(event)

        return "\n".join(f"- {event}" for event in final_events) or "æš‚æ— "

    def get_all_event_memory_for_display(self, user_id: str) -> str:
        """è·å–æ‰€æœ‰äº‹ä»¶è®°å¿†ç”¨äºUIå±•ç¤º"""
        results = self.event_memory_collection.get(where={"user_id": user_id})
        if not results['ids']: return "æš‚æ— äº‹ä»¶è®°å¿†ã€‚"
        
        sorted_events = sorted(zip(results['documents'], results['metadatas']), key=lambda x: x[1]['saved_at'], reverse=True)
        return "\n".join(doc for doc, meta in sorted_events)


    def clear_user_rag_documents(self, user_id: str):
        if self.rag_collection.get(where={"user_id": user_id})['ids']:
            self.rag_collection.delete(where={"user_id": user_id})
            logging.info(f"å·²æ¸…ç©ºç”¨æˆ· {user_id} çš„çŸ¥è¯†åº“ã€‚")

    def get_rag_file_list(self, user_id: str) -> list[str]:
        results = self.rag_collection.get(where={"user_id": user_id})
        if not results['ids']: return []
        return sorted(list({meta['source'] for meta in results['metadatas'] if 'source' in meta}))

    @st.cache_data(show_spinner=False)
    def query_rag_documents(_self, user_id: str, query: str, top_k: int = 3) -> str:
        if not _self.rag_collection.get(where={"user_id": user_id}, limit=1)['ids']: return ""
        results = _self.rag_collection.query(query_texts=[query], where={"user_id": user_id}, n_results=top_k)
        retrieved_docs = results.get("documents", [[]])[0]
        if not retrieved_docs: return ""
        formatted_docs = "\n".join([f"- {doc}" for doc in retrieved_docs])
        return f"ä»ä½ çš„çŸ¥è¯†åº“ä¸­æ‰¾åˆ°ä»¥ä¸‹ç›¸å…³ä¿¡æ¯ï¼š\n{formatted_docs}"
        
    @st.cache_data(show_spinner=False)
    def query_recent_discussions(_self, user_id: str, query: str, top_k: int = 3) -> str:
        if not _self.chat_collection.get(where={"user_id": user_id}, limit=1)['ids']: return "è¯¥ç”¨æˆ·æ²¡æœ‰ä»»ä½•å†å²å¯¹è¯è®°å½•ã€‚"
        results = _self.chat_collection.query(query_texts=[query], where={"user_id": user_id}, n_results=top_k)
        retrieved_docs = results.get("documents", [[]])[0]
        if not retrieved_docs: return "åœ¨ä½ çš„å†å²è®°å½•ä¸­ï¼Œæ²¡æœ‰æ‰¾åˆ°ä¸å½“å‰é—®é¢˜ç›¸å…³çš„å†…å®¹ã€‚"
        formatted_docs = "\n".join([f"- \"{doc}\"" for doc in retrieved_docs])
        return f"ä½ å›å¿†èµ·äº†ä»¥ä¸‹å¯èƒ½ç›¸å…³çš„å†å²å¯¹è¯å†…å®¹ï¼š\n{formatted_docs}"

# --- æ™ºèƒ½ä»£ç†ç±» ---
class ChatAgent:
    def __init__(self, config: Config, db_manager: ChatHistoryDB, api_key: str, user_id: str):
        self.config, self.db_manager, self.api_key, self.user_id = config, db_manager, api_key, user_id
        if not api_key: raise ValueError("å¿…é¡»æä¾› ZHIPU_API_KEYã€‚")
        self.client = OpenAI(api_key=api_key, base_url=self.config.ZHIPU_BASE_URL)
        self.refresh_agent_state()

    def refresh_agent_state(self, query: str = None):
        """åˆ·æ–°ä»£ç†çŠ¶æ€ï¼ŒåŠ è½½æ‰€æœ‰ç±»å‹çš„è®°å¿†"""
        fact_memory = self.db_manager.load_fact_memory(self.user_id)
        event_memory = self.db_manager.load_event_memory(self.user_id, query=query) # V3.0: åŠ è½½äº‹ä»¶è®°å¿†
        
        system_prompt = self.config.SYSTEM_PROMPT_TEMPLATE.format(
            user_id=self.user_id, 
            long_term_memory=fact_memory,
            event_memory=event_memory
        )
        
        self.messages = self.db_manager.load_history_by_user(self.user_id)
        if not self.messages or self.messages[0]['role'] != 'system':
            self.messages.insert(0, {"role": "system", "content": system_prompt})
        else: 
            self.messages[0]['content'] = system_prompt

    def run(self, user_input: str):
        # V3.0: åœ¨è¿è¡Œå‰ï¼Œæ ¹æ®ç”¨æˆ·è¾“å…¥åˆ·æ–°ä¸€æ¬¡è®°å¿†çŠ¶æ€ï¼Œä»¥è·å–æœ€ç›¸å…³çš„äº‹ä»¶
        self.refresh_agent_state(query=user_input)
        
        context_from_rag = self.db_manager.query_rag_documents(self.user_id, user_input)
        context_from_history = self.db_manager.query_recent_discussions(self.user_id, user_input)
        
        messages_for_llm = list(self.messages)
        if context_from_rag: messages_for_llm.append({"role": "system", "content": f"è¡¥å……ä¿¡æ¯-çŸ¥è¯†åº“æ£€ç´¢:\n{context_from_rag}"})
        if context_from_history: messages_for_llm.append({"role": "system", "content": f"è¡¥å……ä¿¡æ¯-å†å²å¯¹è¯å›é¡¾:\n{context_from_history}"})
        
        messages_for_llm.append({"role": "user", "content": user_input})
        
        try:
            response = self.client.chat.completions.create(model=self.config.LLM_MODEL, messages=messages_for_llm)
            final_response = response.choices[0].message.content or "æŠ±æ­‰ï¼Œæˆ‘ä¸çŸ¥é“å¦‚ä½•å›å¤ã€‚"
        except Exception as e:
            logging.error(f"è°ƒç”¨LLM APIå¤±è´¥: {e}")
            final_response = f"æŠ±æ­‰ï¼Œå‡ºé”™äº†: {e}"
            
        user_message = {"role": "user", "content": user_input}
        assistant_message = {"role": "assistant", "content": final_response}
        
        self.db_manager.save_message(self.user_id, user_message)
        self.db_manager.save_message(self.user_id, assistant_message)
        
        self.messages.extend([user_message, assistant_message])
        
        user_message_count = sum(1 for msg in self.messages if msg['role'] == 'user')
        if user_message_count > 0 and user_message_count % self.config.MEMORY_EXTRACTION_INTERVAL == 0:
            self.extract_and_save_memory()
            
        return final_response

    # V3.0: æ ¸å¿ƒå‡½æ•°å‡çº§ï¼Œæå–äº‹å®å’Œäº‹ä»¶
    def extract_and_save_memory(self):
        conversation = [msg for msg in self.messages if msg['role'] in ['user', 'assistant']]
        if len(conversation) < 2: return False
        
        full_chat_content = "\n".join([f"{m['role']}: {m['content']}" for m in conversation])
        
        memory_prompt = f"""
        è¯·ä»”ç»†é˜…è¯»ç”¨æˆ· {self.user_id} çš„å¯¹è¯ï¼Œå¹¶ä»¥JSONæ ¼å¼ï¼Œæç‚¼å‡ºä¸¤ç§ä¿¡æ¯ï¼š
        1.  `static_facts`: å…³äºç”¨æˆ·çš„ã€æ ¸å¿ƒäº‹å®ã€‘ã€ã€é•¿æœŸåå¥½ã€‘æˆ–ã€è‡ªå®šä¹‰çŠ¶æ€ã€‘ã€‚è¿™äº›ä¿¡æ¯æ˜¯ç›¸å¯¹ç¨³å®šçš„ã€‚ä¾‹å¦‚ï¼šå§“åã€èŒä¸šã€çˆ±å¥½ã€å–œæ¬¢çš„é¢œè‰²ã€è§’è‰²æ‰®æ¼”çŠ¶æ€å¦‚â€œç‚¼æ°”æœŸâ€ã€ç‰¹å®šç›®æ ‡ç­‰ã€‚å¦‚æœæ–°ä¿¡æ¯ä¸æ—§ä¿¡æ¯å†²çªï¼Œè¯·åªä¿ç•™æœ€æ–°çš„ã€‚
        2.  `events`: å¯¹è¯ä¸­æåˆ°çš„ã€åŠ¨æ€äº‹ä»¶ã€‘æˆ–ã€æœªæ¥è®¡åˆ’ã€‘ã€‚æ¯ä¸ªäº‹ä»¶åº”åŒ…å«`description`ï¼ˆäº‹ä»¶æè¿°ï¼‰å’Œ`event_time`ï¼ˆé¢„ä¼°çš„å‘ç”Ÿæ—¶é—´ï¼Œå¦‚'2024-08-15 10:00'æˆ–'ä¸‹å‘¨ä¸‰'ï¼‰ã€‚

        å¦‚æœå¯¹è¯ä¸­æ²¡æœ‰å‘ç°ä»»ä½•æ­¤ç±»ä¿¡æ¯ï¼Œè¯·è¿”å›ä¸€ä¸ªç©ºçš„JSONå¯¹è±¡ {{}}ã€‚

        å¯¹è¯å†…å®¹:
        ---
        {full_chat_content}
        ---
        æå–çš„JSONæ ¼å¼ç¤ºä¾‹:
        {{
          "static_facts": {{
            "å§“å": "å¼ ä¸‰",
            "èŒä¸š": "è½¯ä»¶å·¥ç¨‹å¸ˆ",
            "å® ç‰©": "ä¸€åªåå«'æ—ºè´¢'çš„ç‹—"
          }},
          "events": [
            {{
              "description": "ä¸‹å‘¨è¦å»åŒ—äº¬å‡ºå·®",
              "event_time": "ä¸‹å‘¨"
            }},
            {{
              "description": "å®Œæˆäº†é¡¹ç›®Açš„æŠ¥å‘Š",
              "event_time": "æ˜¨å¤©"
            }}
          ]
        }}
        ---
        æå–çš„JSON:
        """
        
        try:
            response = self.client.chat.completions.create(
                model=self.config.LLM_MODEL, 
                messages=[{"role": "user", "content": memory_prompt}], 
                response_format={"type": "json_object"}
            )
            content = response.choices[0].message.content
            if content and (extracted_data := json.loads(content)):
                self.db_manager.save_structured_memory(self.user_id, extracted_data)
                self.refresh_agent_state() # ä¿å­˜åç«‹å³åˆ·æ–°ï¼Œç¡®ä¿ä¸‹ä¸€è½®å¯¹è¯ç”Ÿæ•ˆ
                return True
            return False
        except Exception as e:
            logging.error(f"è§£ææˆ–ä¿å­˜é•¿æœŸè®°å¿†å¤±è´¥: {e}")
            return False

# -----------------------------------------------------------------------------
# æ­¥éª¤ 3: Streamlit å‰ç«¯ç•Œé¢ (V3.1 - å¢åŠ ç¼“å­˜æ¸…ç†å·¥å…·)
# -----------------------------------------------------------------------------

st.set_page_config(page_title="æ‚¨çš„ä¸“å±è®°å¿†åŠ©ç† V3.1", page_icon="ğŸ§ ", layout="centered")

@st.cache_resource
def get_core_services():
    config = Config()
    db_manager = ChatHistoryDB(config)
    return config, db_manager

config, db_manager = get_core_services()
api_key = os.getenv("ZHIPUAI_API_KEY")
if not api_key:
    st.error("æœªæ‰¾åˆ° ZHIPUAI_API_KEY ç¯å¢ƒå˜é‡ï¼Œè¯·é…ç½®ã€‚")
    st.stop()
    
if "logged_in_user_id" not in st.session_state: st.session_state.logged_in_user_id = None
if "agent" not in st.session_state: st.session_state.agent = None

# --- ä¾§è¾¹æ  ---
with st.sidebar:
    st.header("ğŸ‘¤ ç”¨æˆ·ä¸­å¿ƒ")
    user_id_input = st.text_input("è¯·è¾“å…¥æ‚¨çš„ç”¨æˆ·ID", key="user_id_input", placeholder="ä¾‹å¦‚: zhangsan")
    if st.button("ç™»å½• / åˆ‡æ¢ç”¨æˆ·", key="login_button"):
        if user_id_input:
            if st.session_state.agent and st.session_state.logged_in_user_id != user_id_input:
                with st.spinner("æ²‰æ·€æœ€ç»ˆè®°å¿†..."): st.session_state.agent.extract_and_save_memory()
            st.session_state.logged_in_user_id = user_id_input
            st.session_state.agent = None
            st.toast(f"æ¬¢è¿å›æ¥, {user_id_input}ï¼", icon="âœ…")
            st.rerun()
        else: st.warning("è¯·è¾“å…¥ä¸€ä¸ªç”¨æˆ·IDã€‚")

    if st.session_state.logged_in_user_id:
        current_user_id = st.session_state.logged_in_user_id
        st.markdown("---")
        
        st.header("ğŸ“š çŸ¥è¯†åº“ (RAG)")
        uploaded_file = st.file_uploader("ä¸Šä¼ çŸ¥è¯†æ–‡ä»¶ (.txt/.md)", type=['txt', 'md'], key=f"uploader_{current_user_id}")
        
        if uploaded_file:
            progress_bar = st.progress(0, text="å‡†å¤‡ä¸Šä¼ å’Œå­¦ä¹ æ–‡ä»¶...")
            def update_progress(percent, message):
                progress_bar.progress(percent, text=message)
            try:
                content = uploaded_file.getvalue().decode("utf-8")
                db_manager.add_document_to_rag(current_user_id, uploaded_file.name, content, progress_callback=update_progress)
                time.sleep(2)
                st.toast(f"æ–‡ä»¶ '{uploaded_file.name}' å·²å­¦ä¹ å®Œæˆï¼", icon="âœ…")
                st.rerun()
            except Exception as e:
                progress_bar.empty()
                st.error(f"å¤„ç†æ–‡ä»¶å¤±è´¥: {e}")
        
        rag_files = db_manager.get_rag_file_list(current_user_id)
        if rag_files:
            with st.expander("æŸ¥çœ‹å·²ä¸Šä¼ çš„æ–‡ä»¶", expanded=False):
                for f in rag_files: st.caption(f)
            if st.button("ğŸ—‘ï¸ æ¸…ç©ºæ‰€æœ‰çŸ¥è¯†åº“æ–‡ä»¶", key="clear_rag"):
                with st.spinner("æ¸…ç©ºçŸ¥è¯†åº“..."):
                    db_manager.clear_user_rag_documents(current_user_id)
                    st.cache_data.clear()
                st.toast("çŸ¥è¯†åº“å·²æ¸…ç©ºï¼", icon="ğŸ—‘ï¸")
                st.rerun()

        st.markdown("---")
        st.header("ğŸ› ï¸ è®°å¿†å·¥å…·ç®±")
        
        # V3.1: æ–°å¢ç¼“å­˜æ¸…ç†æŒ‰é’®ï¼Œç”¨äºå¼€å‘å’Œè°ƒè¯•
        if st.button("ğŸ”„ æ¸…ç†åº”ç”¨ç¼“å­˜", key="clear_app_cache", help="å½“åº”ç”¨è¡Œä¸ºå¼‚å¸¸æˆ–ä»£ç æ›´æ–°åæœªç”Ÿæ•ˆæ—¶ï¼Œå¯å°è¯•æ¸…ç†ç¼“å­˜ã€‚"):
            st.cache_resource.clear()
            st.cache_data.clear()
            st.session_state.agent = None # å¼ºåˆ¶é‡æ–°åˆå§‹åŒ–agent
            st.toast("åº”ç”¨ç¼“å­˜å·²æ¸…ç†ï¼åº”ç”¨å°†é‡æ–°åŠ è½½ã€‚", icon="â™»ï¸")
            time.sleep(1) # çŸ­æš‚å»¶è¿Ÿä»¥ç¡®ä¿ç”¨æˆ·èƒ½çœ‹åˆ°æç¤º
            st.rerun()

        if st.button("ğŸ§  ä¸»åŠ¨æç‚¼è®°å¿†", key="extract_memory"):
            if st.session_state.agent:
                status_placeholder = st.empty()
                with st.spinner("â³ æ­£åœ¨åˆ†æå’Œæ²‰æ·€è®°å¿†..."):
                    saved = st.session_state.agent.extract_and_save_memory()
                if saved:
                    status_placeholder.success("âœ… è®°å¿†å·²æ›´æ–°ï¼")
                else:
                    status_placeholder.info("ğŸ¤·â€ æœªå‘ç°æ–°çš„å¯è®°å¿†ä¿¡æ¯ã€‚")
                time.sleep(2)
                status_placeholder.empty()
                st.rerun()

        if st.button("ğŸ§¹ æ¸…ç†å½“å‰å¯¹è¯", key="clear_chat"):
            if st.session_state.agent:
                with st.spinner("ä¿å­˜æœ€åçš„å›å¿†..."): st.session_state.agent.extract_and_save_memory()
                with st.spinner("æ¸…ç©ºå¯¹è¯å†å²..."):
                    db_manager.clear_user_chat_history(current_user_id)
                    st.cache_data.clear()
                st.session_state.agent = None
                st.toast("å¯¹è¯å†å²å·²æ¸…ç©ºï¼", icon="ğŸ—‘ï¸")
                st.rerun()
        
        # V3.0: æ‹†åˆ†è®°å¿†å±•ç¤º
        with st.expander("ğŸ‘€ æŸ¥çœ‹æˆ‘çš„é™æ€äº‹å®"):
            memory_content = db_manager.load_fact_memory(current_user_id)
            st.code(memory_content, language=None) if memory_content.strip() and memory_content != "æš‚æ— " else st.info("æš‚æ— é™æ€äº‹å®è®°å¿†ã€‚")

        with st.expander("ğŸ“… æŸ¥çœ‹æˆ‘çš„äº‹ä»¶è®°å¿†"):
            event_memory_content = db_manager.get_all_event_memory_for_display(current_user_id)
            st.code(event_memory_content, language=None) if event_memory_content.strip() and "æš‚æ— " not in event_memory_content else st.info("æš‚æ— äº‹ä»¶è®°å¿†ã€‚")

    else: st.caption("è¯·å…ˆç™»å½•ä»¥ä½¿ç”¨å…¨éƒ¨åŠŸèƒ½ã€‚")

# --- ä¸»èŠå¤©ç•Œé¢ ---
st.title("ğŸ§  æ‚¨çš„ä¸“å±è®°å¿†åŠ©ç† V3.1")
if not st.session_state.logged_in_user_id:
    st.info("ğŸ‘ˆ è¯·åœ¨å·¦ä¾§è¾¹æ è¾“å…¥ç”¨æˆ·IDå¹¶ç™»å½•ã€‚")
    st.stop()
try:
    if st.session_state.agent is None:
        st.session_state.agent = ChatAgent(config, db_manager, api_key, st.session_state.logged_in_user_id)
except Exception as e:
    st.error(f"åˆå§‹åŒ–åŠ©ç†å‡ºé”™: {e}")
    st.stop()

# ä»…æ˜¾ç¤ºç”¨æˆ·å’ŒåŠ©æ‰‹çš„æ¶ˆæ¯
for message in st.session_state.agent.messages:
    if message["role"] in ["user", "assistant"]:
        with st.chat_message(message["role"]): st.markdown(message["content"])

if prompt := st.chat_input(f"æ‚¨å¥½, {st.session_state.logged_in_user_id}, æœ‰ä½•è´µå¹²?"):
    st.chat_message("user").markdown(prompt)
    with st.spinner("æ€è€ƒä¸­..."):
        response = st.session_state.agent.run(prompt)
    with st.chat_message("assistant"):
        st.markdown(response)
    st.rerun()

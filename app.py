# -*- coding: utf-8 -*-
# -----------------------------------------------------------------------------
# æ‚¨çš„ä¸“å±è®°å¿†åŠ©ç† V4.6 - ä¸Šä¼ å±æ€§ä¿®å¤ç‰ˆ
#
# æ›´æ–°æ—¥å¿— (V4.6):
# - BUGä¿®å¤: ä¿®å¤äº†å› ä½¿ç”¨é”™è¯¯çš„ `UploadedFile.id` å±æ€§å¯¼è‡´çš„ `AttributeError`ã€‚ç°åœ¨ä½¿ç”¨æ­£ç¡®çš„ `UploadedFile.file_id`ã€‚
#
# æ›´æ–°æ—¥å¿— (V4.5):
# - BUGä¿®å¤: ä¿®å¤äº†æ–‡ä»¶ä¸Šä¼ åå›  `st.rerun()` å¯¼è‡´çš„é‡å¤å¤„ç†é—®é¢˜ã€‚
#
# æ›´æ–°æ—¥å¿— (V4.4):
# - æ ¸å¿ƒé€»è¾‘é‡æ„: åŒºåˆ†äº†â€œæ°¸ä¹…æ€§é™æ€äº‹å®â€å’Œâ€œä¸´æ—¶æ€§äº‹å®â€ã€‚
# - ç™»å½•ä¼˜åŒ–: ç™»å½•æ—¶åªä¼šæ¸…ç†è¿‡æœŸçš„â€œä¸´æ—¶æ€§äº‹å®â€ï¼Œç”¨æˆ·çš„æ ¸å¿ƒåå¥½å’Œèº«ä»½ä¿¡æ¯å°†è¢«æ°¸ä¹…ä¿ç•™ã€‚
# - AIèƒ½åŠ›å‡çº§: ä¼˜åŒ–äº†è®°å¿†æå–çš„Promptï¼Œä½¿AIèƒ½æ›´å‡†ç¡®åœ°åˆ†ç±»ä¸åŒç±»å‹çš„äº‹å®ã€‚
# -----------------------------------------------------------------------------

# -----------------------------------------------------------------------------
# æ­¥éª¤ 1: å¯¼å…¥æ‰€æœ‰å¿…è¦çš„åº“
# -----------------------------------------------------------------------------
import os
import json
import logging
import time
import datetime
import pytz # ç”¨äºå¤„ç†æ—¶åŒº
import streamlit as st
from openai import OpenAI
from dotenv import load_dotenv
import chromadb
from chromadb.utils import embedding_functions

# -----------------------------------------------------------------------------
# æ­¥éª¤ 2: åç«¯é€»è¾‘ä»£ç  (V4.6 - ä¸Šä¼ å±æ€§ä¿®å¤ç‰ˆ)
# -----------------------------------------------------------------------------

# --- æ—¥å¿—è®°å½•é…ç½® ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# --- æ ¸å¿ƒé…ç½®ç±» ---
class Config:
    """é›†ä¸­ç®¡ç†æ‰€æœ‰é…ç½®"""
    load_dotenv()
    ZHIPU_BASE_URL = "https://open.bigmodel.cn/api/paas/v4/"
    LLM_MODEL = "glm-4-flash"
    EMBEDDING_MODEL = "BAAI/bge-base-zh-v1.5"
    DB_PATH = "/workspace/memoryAgent/user_centric_db_v4.6" # V4.6: æ•°æ®åº“è·¯å¾„æ›´æ–°
    CHAT_COLLECTION_NAME = "user_chat_history"
    FACT_MEMORY_COLLECTION_NAME = "user_fact_memory"
    EVENT_MEMORY_COLLECTION_NAME = "user_event_memory"
    RAG_COLLECTION_NAME = "user_rag_documents"
    TIMEZONE = "Asia/Shanghai"

    SYSTEM_PROMPT_TEMPLATE = """
    ä½ æ˜¯ä¸ºç”¨æˆ· {user_id} æœåŠ¡çš„é¡¶çº§ä¸ªäººæ™ºèƒ½åŠ©æ‰‹ã€‚

    # å½“å‰æ—¶é—´: {current_time}

    # å…³äºç”¨æˆ· {user_id} çš„å·²çŸ¥äº‹å® (ä½ çš„é™æ€è®°å¿†):
    {long_term_memory}

    # å…³äºç”¨æˆ· {user_id} çš„ç›¸å…³äº‹ä»¶ä¸è®¡åˆ’ (ä½ çš„åŠ¨æ€è®°å¿†):
    ## æœªæ¥è®¡åˆ’ (æŒ‰æ—¶é—´æ­£åº):
    {future_events}
    ## æœ€è¿‘å‘ç”Ÿçš„äº‹ä»¶ (æŒ‰æ—¶é—´å€’åº):
    {past_events}

    # ä½ çš„å·¥ä½œæµç¨‹:
    1.  **æ·±å…¥ç†è§£**: ç»“åˆå½“å‰æ—¶é—´ï¼Œåˆ†æç”¨æˆ·çš„æœ€æ–°é—®é¢˜ã€‚
    2.  **æ•´åˆä¿¡æ¯**: æˆ‘ä¼šä¸ºä½ æä¾›ç”¨æˆ·çš„é•¿æœŸäº‹å®è®°å¿†ã€æŒ‰æ—¶é—´æ’åºçš„äº‹ä»¶è®°å¿†ã€ç›¸å…³çš„å†å²å¯¹è¯ã€ä»¥åŠçŸ¥è¯†åº“èµ„æ–™ã€‚ä½ å¿…é¡»å°†è¿™äº›ä¿¡æ¯å…¨éƒ¨æ•´åˆï¼Œå½¢æˆå¯¹ä¸Šä¸‹æ–‡çš„å®Œæ•´ç†è§£ã€‚
    3.  **ä¼˜å…ˆä½¿ç”¨çŸ¥è¯†åº“**: å¦‚æœçŸ¥è¯†åº“ä¿¡æ¯ä¸é—®é¢˜ç›´æ¥ç›¸å…³ï¼Œä¼˜å…ˆåŸºäºè¿™äº›ä¿¡æ¯å›ç­”ã€‚
    4.  **ä¸ªæ€§åŒ–å›ç­”**: åŸºäºæ‰€æœ‰ä¿¡æ¯ï¼Œä¸ºç”¨æˆ· {user_id} ç”Ÿæˆä¸€ä¸ªå¯Œæœ‰æ´å¯ŸåŠ›ã€è¿è´¯ä¸”ä¸ªæ€§åŒ–çš„å›ç­”ã€‚
    """
    
    MEMORY_EXTRACTION_INTERVAL = 4

# --- æ–‡æœ¬åˆ†å‰²å™¨ ---
def simple_text_splitter(text: str, max_chunk_size: int = 500) -> list[str]:
    """ä¸€ä¸ªç®€å•çš„æ–‡æœ¬åˆ†å‰²å™¨ï¼ŒæŒ‰å¥å­åˆ†å‰²"""
    sentences = text.replace("\n", " ").replace("\r", " ").split('ã€‚')
    chunks, current_chunk = [], ""
    for sentence in sentences:
        if not sentence.strip(): continue
        sentence += "ã€‚"
        if len(current_chunk) + len(sentence) <= max_chunk_size:
            current_chunk += sentence
        else:
            chunks.append(current_chunk.strip())
            current_chunk = sentence
    if current_chunk: chunks.append(current_chunk.strip())
    return chunks

# --- æ•°æ®åº“ç®¡ç†ç±» ---
class ChatHistoryDB:
    def __init__(self, config: Config):
        self.config = config
        self.tz = pytz.timezone(config.TIMEZONE)
        try:
            os.makedirs(config.DB_PATH, exist_ok=True)
            self.db_client = chromadb.PersistentClient(path=self.config.DB_PATH)
            self.embedding_func = embedding_functions.SentenceTransformerEmbeddingFunction(
                model_name=self.config.EMBEDDING_MODEL
            )
            self.chat_collection = self.db_client.get_or_create_collection(name=self.config.CHAT_COLLECTION_NAME, embedding_function=self.embedding_func)
            self.fact_memory_collection = self.db_client.get_or_create_collection(name=self.config.FACT_MEMORY_COLLECTION_NAME, embedding_function=self.embedding_func)
            self.event_memory_collection = self.db_client.get_or_create_collection(name=self.config.EVENT_MEMORY_COLLECTION_NAME, embedding_function=self.embedding_func)
            self.rag_collection = self.db_client.get_or_create_collection(name=self.config.RAG_COLLECTION_NAME, embedding_function=self.embedding_func)
            logging.info(f"æ•°æ®åº“åˆå§‹åŒ–æˆåŠŸ: {config.DB_PATH}")
        except Exception as e:
            logging.error(f"åˆå§‹åŒ– ChromaDB å¤±è´¥: {e}")
            st.error(f"æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")
            raise

    def add_document_to_rag(self, user_id: str, file_name: str, file_content: str, progress_callback=None):
        """å°†æ–‡æ¡£æ·»åŠ åˆ°RAGçŸ¥è¯†åº“ï¼Œå¹¶æä¾›æ¸…æ™°çš„è¿›åº¦å›è°ƒ"""
        if progress_callback: progress_callback(0, "æ­¥éª¤ 1/2: æ­£åœ¨åˆ†å‰²æ–‡ä»¶...")
        chunks = simple_text_splitter(file_content)
        if not chunks:
            if progress_callback: progress_callback(100, "æ–‡ä»¶å†…å®¹ä¸ºç©ºï¼Œå·²è·³è¿‡ã€‚")
            return

        total_chunks = len(chunks)
        logging.info(f"æ–‡ä»¶ '{file_name}' è¢«åˆ†å‰²æˆ {total_chunks} ä¸ªç‰‡æ®µã€‚")
        
        if progress_callback: progress_callback(5, f"æ­¥éª¤ 2/2: å‡†å¤‡è®¡ç®—å‘é‡... (å…± {total_chunks} å—)")
        
        batch_size = 32
        for i in range(0, total_chunks, batch_size):
            batch_chunks = chunks[i:i + batch_size]
            batch_ids = [f"rag_{user_id}_{file_name}_{time.time()}_{i+j}" for j in range(len(batch_chunks))]
            batch_metadatas = [{"user_id": user_id, "source": file_name} for _ in batch_chunks]
            
            self.rag_collection.add(ids=batch_ids, documents=batch_chunks, metadatas=batch_metadatas)
            
            if progress_callback:
                processed_count = i + len(batch_chunks)
                percentage = 5 + int((processed_count / total_chunks) * 90)
                status_text = f"æ­¥éª¤ 2/2: æ­£åœ¨è®¡ç®—å‘é‡... ({processed_count}/{total_chunks})"
                progress_callback(min(percentage, 95), status_text)
        
        if progress_callback: progress_callback(100, "çŸ¥è¯†åº“å­¦ä¹ å®Œæˆï¼")
        logging.info(f"æ–‡ä»¶ '{file_name}' å·²æˆåŠŸæ·»åŠ è‡³çŸ¥è¯†åº“ã€‚")

    def save_message(self, user_id: str, message: dict):
        if not all(k in message for k in ['role', 'content']) or not message.get('content'): return
        timestamp = time.time()
        doc_id = f"msg_{user_id}_{timestamp}"
        self.chat_collection.add(ids=[doc_id], documents=[message['content']], metadatas=[{"user_id": user_id, "role": message['role'], "timestamp": timestamp}])

    def load_history_by_user(self, user_id: str) -> list:
        if not user_id: return []
        results = self.chat_collection.get(where={"user_id": user_id})
        if not results['ids']: return []
        packaged_messages = sorted([{"doc": results['documents'][i], "meta": results['metadatas'][i]} for i in range(len(results['ids']))], key=lambda m: m['meta']['timestamp'])
        return [{"role": msg['meta']['role'], "content": msg['doc']} for msg in packaged_messages]

    def clear_user_chat_history(self, user_id: str):
        if self.chat_collection.get(where={"user_id": user_id})['ids']:
            self.chat_collection.delete(where={"user_id": user_id})
            logging.info(f"å·²æ¸…ç©ºç”¨æˆ· {user_id} çš„å¯¹è¯å†å²ã€‚")

    def clear_old_temporal_fact_memory(self, user_id: str):
        """æ¸…é™¤æŒ‡å®šç”¨æˆ·ä»Šå¤©ä¹‹å‰çš„ã€ä¸´æ—¶ã€‘äº‹å®è®°å¿†ï¼Œä¿ç•™æ°¸ä¹…æ€§é™æ€äº‹å®ã€‚"""
        logging.info(f"å¼€å§‹ä¸ºç”¨æˆ· {user_id} æ¸…ç†æ—§çš„ã€ä¸´æ—¶ã€‘äº‹å®è®°å¿†...")
        
        today_start = datetime.datetime.now(self.tz).replace(hour=0, minute=0, second=0, microsecond=0)
        today_start_timestamp = today_start.timestamp()

        results = self.fact_memory_collection.get(where={"user_id": user_id})
        if not results['ids']:
            logging.info(f"ç”¨æˆ· {user_id} æ²¡æœ‰äº‹å®è®°å¿†å¯æ¸…ç†ã€‚")
            return

        ids_to_delete = [
            results['ids'][i] 
            for i, meta in enumerate(results['metadatas']) 
            # æ ¸å¿ƒæ¡ä»¶: åªåˆ é™¤ (is_permanentä¸ä¸ºTrue) ä¸” (æ—¶é—´æˆ³æ—©äºä»Šå¤©) çš„è®°å¿†
            if meta.get('is_permanent') is not True and meta.get('timestamp') and meta['timestamp'] < today_start_timestamp
        ]

        if ids_to_delete:
            logging.info(f"ä¸ºç”¨æˆ· {user_id} æ‰¾åˆ° {len(ids_to_delete)} æ¡æ—§çš„ä¸´æ—¶äº‹å®è®°å¿†ï¼Œå‡†å¤‡åˆ é™¤...")
            self.fact_memory_collection.delete(ids=ids_to_delete)
            logging.info(f"å·²æˆåŠŸä¸ºç”¨æˆ· {user_id} æ¸…ç†äº† {len(ids_to_delete)} æ¡æ—§çš„ä¸´æ—¶äº‹å®è®°å¿†ã€‚")
        else:
            logging.info(f"ç”¨æˆ· {user_id} æ²¡æœ‰ä»Šå¤©ä¹‹å‰çš„æ—§ä¸´æ—¶äº‹å®è®°å¿†å¯æ¸…ç†ã€‚")
            
    def save_structured_memory(self, user_id: str, memory_data: dict):
        """ä¿å­˜ç»“æ„åŒ–çš„è®°å¿†ï¼ŒåŒºåˆ†æ°¸ä¹…äº‹å®ã€ä¸´æ—¶äº‹å®å’ŒåŠ¨æ€äº‹ä»¶"""

        def _save_facts(facts: dict, is_permanent: bool):
            if not (facts and isinstance(facts, dict)):
                return
            
            fact_type_str = "æ°¸ä¹…" if is_permanent else "ä¸´æ—¶"
            logging.info(f"æ­£åœ¨ä¸ºç”¨æˆ· {user_id} ä¿å­˜æˆ–æ›´æ–° {len(facts)} æ¡{fact_type_str}äº‹å®è®°å¿†...")
            
            items_to_save = []
            for key, value in facts.items():
                if isinstance(value, dict):
                    for sub_key, sub_value in value.items():
                        items_to_save.append((f"{key}_{sub_key}", sub_value))
                else:
                    items_to_save.append((key, value))
            
            for key, value in items_to_save:
                doc_id = f"fact_{user_id}_{key}"
                self.fact_memory_collection.upsert(
                    ids=[doc_id],
                    documents=[f"ç”¨æˆ·çš„ä¸ªäººä¿¡æ¯ï¼š{key} æ˜¯ {value}ã€‚"],
                    metadatas=[{
                        "user_id": user_id, 
                        "key": key, 
                        "timestamp": time.time(),
                        "is_permanent": is_permanent  # æ–°å¢çš„å…³é”®å…ƒæ•°æ®å­—æ®µ
                    }]
                )

        # å¤„ç†æ°¸ä¹…æ€§äº‹å®
        permanent_facts = memory_data.get('permanent_facts', {})
        _save_facts(permanent_facts, is_permanent=True)

        # å¤„ç†ä¸´æ—¶æ€§äº‹å® (å¹¶å…¼å®¹æ—§çš„ static_facts é”®)
        temporal_facts = memory_data.get('temporal_facts', {})
        if not temporal_facts and 'static_facts' in memory_data:
             temporal_facts = memory_data.get('static_facts', {}) # å‘åå…¼å®¹
        _save_facts(temporal_facts, is_permanent=False)

        # äº‹ä»¶å¤„ç†é€»è¾‘ä¿æŒä¸å˜
        events = memory_data.get('events', [])
        if events and isinstance(events, list):
            logging.info(f"æ­£åœ¨ä¸ºç”¨æˆ· {user_id} ä¿å­˜ {len(events)} æ¡äº‹ä»¶è®°å¿†...")
            for event in events:
                if isinstance(event, dict) and 'description' in event and 'event_time_iso' in event:
                    description = event['description']
                    event_time_iso = event['event_time_iso']
                    event_time_desc = event.get('event_time_desc', 'æœªçŸ¥æ—¶é—´')
                    
                    doc_id = f"event_{user_id}_{time.time()}"
                    self.event_memory_collection.add(
                        ids=[doc_id],
                        documents=[f"äº‹ä»¶: {description} (æ—¶é—´: {event_time_desc})"],
                        metadatas={
                            "user_id": user_id, 
                            "event_time_iso": event_time_iso,
                            "event_time_desc": event_time_desc,
                            "saved_at": time.time()
                        }
                    )

    def load_fact_memory(self, user_id: str, top_k: int = 20) -> str:
        """åŠ è½½é™æ€äº‹å®è®°å¿†"""
        results = self.fact_memory_collection.get(where={"user_id": user_id}, limit=top_k)
        return "\n".join(f"- {doc}" for doc in results.get('documents', [])) or "æš‚æ— "
    
    def load_event_memory(self, user_id: str, query: str = None) -> tuple[str, str]:
        """
        åŠ è½½ä¸ç”¨æˆ·ç›¸å…³çš„äº‹ä»¶è®°å¿†ï¼Œç²¾ç¡®åŒºåˆ†æœªæ¥å’Œè¿‡å»ã€‚
        è¿”å›ä¸€ä¸ªå…ƒç»„: (æœªæ¥äº‹ä»¶å­—ç¬¦ä¸², è¿‡å»äº‹ä»¶å­—ç¬¦ä¸²)
        """
        if not user_id: return "æš‚æ— ", "æš‚æ— "
        
        all_events_result = self.event_memory_collection.get(where={"user_id": user_id})
        if not all_events_result['ids']: return "æš‚æ— ", "æš‚æ— "

        now = datetime.datetime.now(self.tz)
        future_events, past_events = [], []

        for i, meta in enumerate(all_events_result['metadatas']):
            event_time_iso = meta.get('event_time_iso')
            if not event_time_iso: continue
            
            try:
                if 'Z' in event_time_iso or '+' in event_time_iso or '-' in event_time_iso[10:]:
                    event_dt = datetime.datetime.fromisoformat(event_time_iso)
                else:
                    event_dt = self.tz.localize(datetime.datetime.fromisoformat(event_time_iso))
            except (ValueError, TypeError):
                continue

            event_record = (event_dt, all_events_result['documents'][i])
            if event_dt > now:
                future_events.append(event_record)
            else:
                past_events.append(event_record)

        future_events.sort(key=lambda x: x[0])
        past_events.sort(key=lambda x: x[0], reverse=True)

        future_str = "\n".join(f"- {doc} (æ—¶é—´: {dt.strftime('%Y-%m-%d %H:%M')})" for dt, doc in future_events) or "æš‚æ— "
        past_str = "\n".join(f"- {doc} (æ—¶é—´: {dt.strftime('%Y-%m-%d %H:%M')})" for dt, doc in past_events[:5]) or "æš‚æ— "

        return future_str, past_str

    def get_all_event_memory_for_display(self, user_id: str) -> str:
        """è·å–æ‰€æœ‰äº‹ä»¶è®°å¿†ç”¨äºUIå±•ç¤ºï¼Œå¹¶æŒ‰æ—¶é—´æ’åº"""
        results = self.event_memory_collection.get(where={"user_id": user_id})
        if not results['ids']: return "æš‚æ— äº‹ä»¶è®°å¿†ã€‚"
        
        events_with_time = []
        for i, meta in enumerate(results['metadatas']):
            event_time_iso = meta.get('event_time_iso')
            doc = results['documents'][i]
            try:
                dt = datetime.datetime.fromisoformat(event_time_iso.replace('Z', '+00:00')) if event_time_iso else datetime.datetime.min
                events_with_time.append((dt, doc))
            except ValueError:
                events_with_time.append((datetime.datetime.min, f"{doc} (æ—¶é—´è§£æå¤±è´¥: {event_time_iso})"))
        
        events_with_time.sort(key=lambda x: x[0], reverse=True)
        return "\n".join(f"{doc}" for dt, doc in events_with_time)

    def clear_user_rag_documents(self, user_id: str):
        if self.rag_collection.get(where={"user_id": user_id})['ids']:
            self.rag_collection.delete(where={"user_id": user_id})
            logging.info(f"å·²æ¸…ç©ºç”¨æˆ· {user_id} çš„çŸ¥è¯†åº“ã€‚")

    def get_rag_file_list(self, user_id: str) -> list[str]:
        results = self.rag_collection.get(where={"user_id": user_id})
        if not results['ids']: return []
        return sorted(list({meta['source'] for meta in results['metadatas'] if 'source' in meta}))

    @st.cache_data(show_spinner=False)
    def query_rag_documents(_self, user_id: str, query: str, top_k: int = 3) -> str:
        if not _self.rag_collection.get(where={"user_id": user_id}, limit=1)['ids']: return ""
        results = _self.rag_collection.query(query_texts=[query], where={"user_id": user_id}, n_results=top_k)
        retrieved_docs = results.get("documents", [[]])[0]
        if not retrieved_docs: return ""
        return f"ä»ä½ çš„çŸ¥è¯†åº“ä¸­æ‰¾åˆ°ä»¥ä¸‹ç›¸å…³ä¿¡æ¯ï¼š\n" + "\n".join(f"- {doc}" for doc in retrieved_docs)
        
    @st.cache_data(show_spinner=False)
    def query_recent_discussions(_self, user_id: str, query: str, top_k: int = 3) -> str:
        if not _self.chat_collection.get(where={"user_id": user_id}, limit=1)['ids']: return "è¯¥ç”¨æˆ·æ²¡æœ‰ä»»ä½•å†å²å¯¹è¯è®°å½•ã€‚"
        results = _self.chat_collection.query(query_texts=[query], where={"user_id": user_id}, n_results=top_k)
        retrieved_docs = results.get("documents", [[]])[0]
        if not retrieved_docs: return "åœ¨ä½ çš„å†å²è®°å½•ä¸­ï¼Œæ²¡æœ‰æ‰¾åˆ°ä¸å½“å‰é—®é¢˜ç›¸å…³çš„å†…å®¹ã€‚"
        return f"ä½ å›å¿†èµ·äº†ä»¥ä¸‹å¯èƒ½ç›¸å…³çš„å†å²å¯¹è¯å†…å®¹ï¼š\n" + "\n".join(f"- \"{doc}\"" for doc in retrieved_docs)

# --- æ™ºèƒ½ä»£ç†ç±» ---
class ChatAgent:
    def __init__(self, config: Config, db_manager: ChatHistoryDB, api_key: str, user_id: str):
        self.config, self.db_manager, self.api_key, self.user_id = config, db_manager, api_key, user_id
        self.tz = pytz.timezone(config.TIMEZONE)
        if not api_key: raise ValueError("å¿…é¡»æä¾› ZHIPU_API_KEYã€‚")
        self.client = OpenAI(api_key=api_key, base_url=self.config.ZHIPU_BASE_URL)
        self.refresh_agent_state()

    def refresh_agent_state(self, query: str = None):
        """åˆ·æ–°ä»£ç†çŠ¶æ€ï¼ŒåŠ è½½æ‰€æœ‰ç±»å‹çš„è®°å¿†å¹¶æ³¨å…¥å½“å‰æ—¶é—´"""
        fact_memory = self.db_manager.load_fact_memory(self.user_id)
        future_events, past_events = self.db_manager.load_event_memory(self.user_id, query=query)
        
        now_time = datetime.datetime.now(self.tz)
        current_time_str = now_time.strftime('%Y-%m-%d %H:%M:%S %Z')

        system_prompt = self.config.SYSTEM_PROMPT_TEMPLATE.format(
            user_id=self.user_id,
            current_time=current_time_str,
            long_term_memory=fact_memory,
            future_events=future_events,
            past_events=past_events
        )
        
        self.messages = self.db_manager.load_history_by_user(self.user_id)
        if not self.messages or self.messages[0]['role'] != 'system':
            self.messages.insert(0, {"role": "system", "content": system_prompt})
        else:
            self.messages[0]['content'] = system_prompt

    def run(self, user_input: str):
        self.refresh_agent_state(query=user_input)
        
        context_from_rag = self.db_manager.query_rag_documents(self.user_id, user_input)
        context_from_history = self.db_manager.query_recent_discussions(self.user_id, user_input)
        
        messages_for_llm = list(self.messages)
        if context_from_rag: messages_for_llm.append({"role": "system", "content": f"è¡¥å……ä¿¡æ¯-çŸ¥è¯†åº“æ£€ç´¢:\n{context_from_rag}"})
        if context_from_history: messages_for_llm.append({"role": "system", "content": f"è¡¥å……ä¿¡æ¯-å†å²å¯¹è¯å›é¡¾:\n{context_from_history}"})
        
        messages_for_llm.append({"role": "user", "content": user_input})
        
        try:
            response = self.client.chat.completions.create(model=self.config.LLM_MODEL, messages=messages_for_llm)
            final_response = response.choices[0].message.content or "æŠ±æ­‰ï¼Œæˆ‘ä¸çŸ¥é“å¦‚ä½•å›å¤ã€‚"
        except Exception as e:
            logging.error(f"è°ƒç”¨LLM APIå¤±è´¥: {e}")
            final_response = f"æŠ±æ­‰ï¼Œå‡ºé”™äº†: {e}"
            
        user_message = {"role": "user", "content": user_input}
        assistant_message = {"role": "assistant", "content": final_response}
        
        self.db_manager.save_message(self.user_id, user_message)
        self.db_manager.save_message(self.user_id, assistant_message)
        
        self.messages.extend([user_message, assistant_message])
        
        user_message_count = sum(1 for msg in self.messages if msg['role'] == 'user')
        if user_message_count > 0 and user_message_count % self.config.MEMORY_EXTRACTION_INTERVAL == 0:
            self.extract_and_save_memory()
            
        return final_response

    def extract_and_save_memory(self):
        conversation = [msg for msg in self.messages if msg['role'] in ['user', 'assistant']]
        if len(conversation) < 2: return False
        
        full_chat_content = "\n".join([f"{m['role']}: {m['content']}" for m in conversation])
        
        now_time = datetime.datetime.now(self.tz)
        current_time_iso = now_time.isoformat()

        # æ›´æ–°åçš„Promptï¼Œè¦æ±‚LLMåŒºåˆ†æ°¸ä¹…æ€§å’Œä¸´æ—¶æ€§äº‹å®
        memory_prompt = f"""
        è¯·ä»”ç»†é˜…è¯»ç”¨æˆ· {self.user_id} çš„å¯¹è¯ï¼Œå¹¶ä»¥JSONæ ¼å¼ï¼Œæç‚¼å‡ºä¸‰ç§ä¿¡æ¯ï¼š
        1.  `permanent_facts`: å…³äºç”¨æˆ·çš„ã€æ ¸å¿ƒäº‹å®ã€‘å’Œã€é•¿æœŸåå¥½ã€‘ã€‚è¿™äº›ä¿¡æ¯éå¸¸ç¨³å®šï¼Œå‡ ä¹ä¸ä¼šæ”¹å˜ï¼ˆä¾‹å¦‚ï¼šå§“åã€èŒä¸šã€å‡ºç”Ÿåœ°ã€åŸºæœ¬ä»·å€¼è§‚ã€ä¸å–œæ¬¢çš„é£Ÿç‰©ï¼‰ã€‚
        2.  `temporal_facts`: å…³äºç”¨æˆ·çš„ã€ä¸´æ—¶çŠ¶æ€ã€‘æˆ–ã€è¿‘æœŸäº‹å®ã€‘ã€‚è¿™äº›ä¿¡æ¯åœ¨çŸ­æœŸå†…æœ‰æ•ˆï¼Œä½†å¯èƒ½å¾ˆå¿«è¿‡æ—¶ï¼ˆä¾‹å¦‚ï¼šä»Šå¤©çš„å¿ƒæƒ…ã€æœ€è¿‘å®Œæˆçš„ä»»åŠ¡ã€æœ¬å‘¨çš„ç›®æ ‡ï¼‰ã€‚
        3.  `events`: å¯¹è¯ä¸­æåˆ°çš„ã€æœªæ¥è®¡åˆ’ã€‘æˆ–ã€å·²ç»å‘ç”Ÿçš„å…·ä½“äº‹ä»¶ã€‘ã€‚

        **é‡è¦è§„åˆ™**:
        - å¯¹äºæ¯ä¸ª`event`ï¼Œå¿…é¡»åŒ…å«ä¸‰ä¸ªå­—æ®µï¼š
          1. `description`: äº‹ä»¶çš„æ–‡å­—æè¿°ã€‚
          2. `event_time_desc`: å¯¹è¯ä¸­æåˆ°çš„åŸå§‹æ—¶é—´æè¿°ï¼ˆå¦‚â€œæ˜å¤©ä¸‹åˆâ€ï¼‰ã€‚
          3. `event_time_iso`: **å¿…é¡»åŸºäºå½“å‰æ—¶é—´ `{current_time_iso}` å°† `event_time_desc` è§£æä¸ºæ ‡å‡†çš„ ISO 8601 æ ¼å¼æ—¶é—´æˆ³ (YYYY-MM-DDTHH:MM:SSÂ±HH:MM)**ã€‚
        - `permanent_facts` å’Œ `temporal_facts` éƒ½åº”è¯¥æ˜¯é”®å€¼å¯¹å½¢å¼çš„JSONå¯¹è±¡ã€‚
        - å¦‚æœå¯¹è¯ä¸­æ²¡æœ‰å‘ç°ä»»ä½•ç‰¹å®šç±»å‹çš„ä¿¡æ¯ï¼Œè¯·è®©å…¶å¯¹åº”çš„å€¼ä¸ºç©ºçš„JSONå¯¹è±¡æˆ–æ•°ç»„ã€‚ä¾‹å¦‚: {{"permanent_facts": {{}}, "temporal_facts": {{"mood": "happy"}}, "events": []}}

        å¯¹è¯å†…å®¹:
        ---
        {full_chat_content}
        ---
        æå–çš„JSON:
        """
        
        try:
            response = self.client.chat.completions.create(
                model=self.config.LLM_MODEL,
                messages=[{"role": "user", "content": memory_prompt}],
                response_format={"type": "json_object"}
            )
            content = response.choices[0].message.content
            if content and (extracted_data := json.loads(content)):
                self.db_manager.save_structured_memory(self.user_id, extracted_data)
                self.refresh_agent_state()
                return True
            return False
        except Exception as e:
            logging.error(f"è§£ææˆ–ä¿å­˜é•¿æœŸè®°å¿†å¤±è´¥: {e}")
            return False

# -----------------------------------------------------------------------------
# æ­¥éª¤ 3: Streamlit å‰ç«¯ç•Œé¢ (V4.6 - ä¸Šä¼ å±æ€§ä¿®å¤ç‰ˆ)
# -----------------------------------------------------------------------------

st.set_page_config(page_title="æ‚¨çš„ä¸“å±è®°å¿†åŠ©ç† V4.6", page_icon="ğŸ§ ", layout="centered")

@st.cache_resource
def get_core_services():
    config = Config()
    db_manager = ChatHistoryDB(config)
    return config, db_manager

config, db_manager = get_core_services()
api_key = os.getenv("ZHIPUAI_API_KEY")
if not api_key:
    st.error("æœªæ‰¾åˆ° ZHIPUAI_API_KEY ç¯å¢ƒå˜é‡ï¼Œè¯·é…ç½®ã€‚")
    st.stop()
    
if "logged_in_user_id" not in st.session_state: st.session_state.logged_in_user_id = None
if "agent" not in st.session_state: st.session_state.agent = None
if "last_uploaded_file_id" not in st.session_state: st.session_state.last_uploaded_file_id = None

# --- ä¾§è¾¹æ  ---
with st.sidebar:
    st.header("ğŸ‘¤ ç”¨æˆ·ä¸­å¿ƒ")
    user_id_input = st.text_input("è¯·è¾“å…¥æ‚¨çš„ç”¨æˆ·ID", key="user_id_input", placeholder="ä¾‹å¦‚: zhangsan")
    if st.button("ç™»å½• / åˆ‡æ¢ç”¨æˆ·", key="login_button"):
        if user_id_input:
            if st.session_state.agent and st.session_state.logged_in_user_id != user_id_input:
                with st.spinner("æ²‰æ·€æœ€ç»ˆè®°å¿†..."): st.session_state.agent.extract_and_save_memory()
            
            st.session_state.logged_in_user_id = user_id_input
            
            # æ›´æ–°äº†æç¤ºæ–‡æœ¬å’Œè°ƒç”¨çš„å‡½æ•°
            with st.spinner(f"æ­£åœ¨ä¸ºæ‚¨æ¸…ç†è¿‡æœŸçš„ä¸´æ—¶è®°å¿†..."):
                db_manager.clear_old_temporal_fact_memory(user_id_input)
                time.sleep(1)

            st.session_state.agent = None
            st.toast(f"æ¬¢è¿å›æ¥, {user_id_input}ï¼æ‚¨çš„è®°å¿†å·²åˆ·æ–°ã€‚", icon="âœ…")
            st.rerun()
        else: st.warning("è¯·è¾“å…¥ä¸€ä¸ªç”¨æˆ·IDã€‚")

    if st.session_state.logged_in_user_id:
        current_user_id = st.session_state.logged_in_user_id
        st.markdown("---")
        
        st.header("ğŸ“š çŸ¥è¯†åº“ (RAG)")
        uploaded_file = st.file_uploader("ä¸Šä¼ çŸ¥è¯†æ–‡ä»¶ (.txt/.md)", type=['txt', 'md'], key=f"uploader_{current_user_id}")
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯æ–°ä¸Šä¼ çš„æ–‡ä»¶ï¼Œä¸”å°šæœªè¢«å¤„ç†
        if uploaded_file is not None and uploaded_file.file_id != st.session_state.get('last_uploaded_file_id'):
            progress_container = st.empty()
            try:
                def update_progress(percent, message):
                    progress_container.progress(percent, text=message)
                
                content = uploaded_file.getvalue().decode("utf-8")
                db_manager.add_document_to_rag(current_user_id, uploaded_file.name, content, progress_callback=update_progress)
                
                # æ ‡è®°æ–‡ä»¶å·²å¤„ç†
                st.session_state.last_uploaded_file_id = uploaded_file.file_id
                
                time.sleep(1) # çŸ­æš‚æ˜¾ç¤ºå®ŒæˆçŠ¶æ€
                progress_container.empty()
                st.toast(f"æ–‡ä»¶ '{uploaded_file.name}' å·²å­¦ä¹ å®Œæˆï¼", icon="âœ…")
                st.rerun() # å®‰å…¨åœ°åˆ·æ–°ç•Œé¢
            except Exception as e:
                # å³ä½¿å¤±è´¥ä¹Ÿè¦æ ‡è®°ï¼Œé˜²æ­¢æ— é™é‡è¯•
                st.session_state.last_uploaded_file_id = uploaded_file.file_id
                progress_container.empty()
                st.error(f"å¤„ç†æ–‡ä»¶å¤±è´¥: {e}")
        
        rag_files = db_manager.get_rag_file_list(current_user_id)
        if rag_files:
            with st.expander("æŸ¥çœ‹å·²ä¸Šä¼ çš„æ–‡ä»¶", expanded=False):
                for f in rag_files: st.caption(f)
            if st.button("ğŸ—‘ï¸ æ¸…ç©ºæ‰€æœ‰çŸ¥è¯†åº“æ–‡ä»¶", key="clear_rag"):
                with st.spinner("æ¸…ç©ºçŸ¥è¯†åº“..."):
                    db_manager.clear_user_rag_documents(current_user_id)
                    st.cache_data.clear()
                st.toast("çŸ¥è¯†åº“å·²æ¸…ç©ºï¼", icon="ğŸ—‘ï¸")
                st.rerun()

        st.markdown("---")
        st.header("ğŸ› ï¸ è®°å¿†å·¥å…·ç®±")
        
        if st.button("ğŸ”„ æ¸…ç†åº”ç”¨ç¼“å­˜", key="clear_app_cache", help="å½“åº”ç”¨è¡Œä¸ºå¼‚å¸¸æˆ–ä»£ç æ›´æ–°åæœªç”Ÿæ•ˆæ—¶ï¼Œå¯å°è¯•æ¸…ç†ç¼“å­˜ã€‚"):
            st.cache_resource.clear()
            st.cache_data.clear()
            st.session_state.agent = None
            st.toast("åº”ç”¨ç¼“å­˜å·²æ¸…ç†ï¼åº”ç”¨å°†é‡æ–°åŠ è½½ã€‚", icon="â™»ï¸")
            time.sleep(1)
            st.rerun()

        if st.button("ğŸ§  ä¸»åŠ¨æç‚¼è®°å¿†", key="extract_memory"):
            if st.session_state.agent:
                with st.spinner("â³ æ­£åœ¨åˆ†æå’Œæ²‰æ·€è®°å¿†..."):
                    saved = st.session_state.agent.extract_and_save_memory()
                if saved:
                    st.success("âœ… è®°å¿†å·²æ›´æ–°ï¼")
                else:
                    st.info("ğŸ¤·â€ æœªå‘ç°æ–°çš„å¯è®°å¿†ä¿¡æ¯ã€‚")
                time.sleep(2)
                st.rerun()

        if st.button("ğŸ§¹ æ¸…ç†å½“å‰å¯¹è¯", key="clear_chat"):
            if st.session_state.agent:
                with st.spinner("ä¿å­˜æœ€åçš„å›å¿†..."): st.session_state.agent.extract_and_save_memory()
                with st.spinner("æ¸…ç©ºå¯¹è¯å†å²..."):
                    db_manager.clear_user_chat_history(current_user_id)
                    st.cache_data.clear()
                st.session_state.agent = None
                st.toast("å¯¹è¯å†å²å·²æ¸…ç©ºï¼", icon="ğŸ—‘ï¸")
                st.rerun()
        
        with st.expander("ğŸ‘€ æŸ¥çœ‹æˆ‘çš„äº‹å®è®°å¿† (åŒ…å«æ°¸ä¹…å’Œä¸´æ—¶)"):
            memory_content = db_manager.load_fact_memory(current_user_id)
            st.code(memory_content, language=None) if memory_content.strip() and memory_content != "æš‚æ— " else st.info("æš‚æ— äº‹å®è®°å¿†ã€‚")

        with st.expander("ğŸ“… æŸ¥çœ‹æˆ‘çš„äº‹ä»¶è®°å¿† (æŒ‰æ—¶é—´å€’åº)"):
            event_memory_content = db_manager.get_all_event_memory_for_display(current_user_id)
            st.code(event_memory_content, language=None) if event_memory_content.strip() and "æš‚æ— " not in event_memory_content else st.info("æš‚æ— äº‹ä»¶è®°å¿†ã€‚")

    else: st.caption("è¯·å…ˆç™»å½•ä»¥ä½¿ç”¨å…¨éƒ¨åŠŸèƒ½ã€‚")

# --- ä¸»èŠå¤©ç•Œé¢ ---
st.title("ğŸ§  æ‚¨çš„ä¸“å±è®°å¿†åŠ©ç† V4.6")
st.caption("ç°åœ¨æˆ‘èƒ½åŒºåˆ†å¹¶æ°¸ä¹…ä¿ç•™æ‚¨çš„æ ¸å¿ƒè®°å¿†äº†ï¼æ¯æ¬¡ç™»å½•ä»…ä¼šæ¸…ç†è¿‡æœŸçš„ä¸´æ—¶è®°å¿†ã€‚")
if not st.session_state.logged_in_user_id:
    st.info("ğŸ‘ˆ è¯·åœ¨å·¦ä¾§è¾¹æ è¾“å…¥ç”¨æˆ·IDå¹¶ç™»å½•ã€‚")
    st.stop()
try:
    if st.session_state.agent is None:
        st.session_state.agent = ChatAgent(config, db_manager, api_key, st.session_state.logged_in_user_id)
except Exception as e:
    st.error(f"åˆå§‹åŒ–åŠ©ç†å‡ºé”™: {e}")
    st.stop()

for message in st.session_state.agent.messages:
    if message["role"] in ["user", "assistant"]:
        with st.chat_message(message["role"]): st.markdown(message["content"])

if prompt := st.chat_input(f"æ‚¨å¥½, {st.session_state.logged_in_user_id}, æœ‰ä½•è´µå¹²?"):
    st.chat_message("user").markdown(prompt)
    with st.spinner("æ€è€ƒä¸­..."):
        response = st.session_state.agent.run(prompt)
    with st.chat_message("assistant"):
        st.markdown(response)
    st.rerun()

# -*- coding: utf-8 -*-
# -----------------------------------------------------------------------------
# æ‚¨çš„ä¸“å±è®°å¿†ä¼™ä¼´ V4.9 - æ—¶åŒºä¿®å¤ç‰ˆ
#
# æ›´æ–°æ—¥å¿— (V4.9):
# - BUGä¿®å¤: å½»åº•è§£å†³äº†å› æ··åˆâ€œæœ‰/æ— æ—¶åŒºä¿¡æ¯â€çš„datetimeå¯¹è±¡è€Œå¯¼è‡´çš„ `TypeError`ã€‚
# - ç»Ÿä¸€æ—¶é—´æ ‡å‡†: æ‰€æœ‰æ—¶é—´åœ¨å¤„ç†å‰éƒ½ä¼šè¢«ç»Ÿä¸€è½¬æ¢ä¸ºâ€œæœ‰æ—¶åŒºä¿¡æ¯â€çš„æ ¼å¼ï¼Œæœç»äº†æ¯”è¾ƒé”™è¯¯ã€‚
# - å¢å¼ºå…¼å®¹æ€§: ä¼˜åŒ–äº†æ—¶é—´è§£æé€»è¾‘ï¼Œæé«˜äº†å¯¹ä¸åŒæ—¶é—´æ ¼å¼çš„å…¼å®¹æ€§ã€‚
#
# æ›´æ–°æ—¥å¿— (V4.8):
# - AIè§’è‰²é‡å¡‘: å°†AIä»â€œçŸ¥è¯†åŠ©æ‰‹â€è½¬å˜ä¸ºâ€œç§äººä¼™ä¼´â€ï¼Œä¼˜åŒ–äº¤äº’ä½“éªŒã€‚
# -----------------------------------------------------------------------------

# -----------------------------------------------------------------------------
# æ­¥éª¤ 1: å¯¼å…¥æ‰€æœ‰å¿…è¦çš„åº“
# -----------------------------------------------------------------------------
import os
import json
import logging
import time
import datetime
import pytz # ç”¨äºå¤„ç†æ—¶åŒº
import streamlit as st
from openai import OpenAI
from dotenv import load_dotenv
import chromadb
from chromadb.utils import embedding_functions

# -----------------------------------------------------------------------------
# æ­¥éª¤ 2: åç«¯é€»è¾‘ä»£ç  (V4.9 - æ—¶åŒºä¿®å¤ç‰ˆ)
# -----------------------------------------------------------------------------

# --- æ—¥å¿—è®°å½•é…ç½® ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# --- æ ¸å¿ƒé…ç½®ç±» ---
class Config:
    """é›†ä¸­ç®¡ç†æ‰€æœ‰é…ç½®"""
    load_dotenv()
    ZHIPU_BASE_URL = "https://open.bigmodel.cn/api/paas/v4/"
    LLM_MODEL = "glm-4-flash"
    EMBEDDING_MODEL = "BAAI/bge-base-zh-v1.5"
    DB_PATH = "/workspace/memoryAgent/user_centric_db_v4.9" # V4.9: æ•°æ®åº“è·¯å¾„æ›´æ–°
    CHAT_COLLECTION_NAME = "user_chat_history"
    FACT_MEMORY_COLLECTION_NAME = "user_fact_memory"
    EVENT_MEMORY_COLLECTION_NAME = "user_event_memory"
    RAG_COLLECTION_NAME = "user_rag_documents"
    TIMEZONE = "Asia/Shanghai"

    SYSTEM_PROMPT_TEMPLATE = """
    ä½ æ˜¯ä¸€ä½ä¸ºç”¨æˆ· {user_id} æœåŠ¡çš„ã€å……æ»¡æ¸©åº¦ä¸æ”¯æŒçš„ç§äººä¼™ä¼´ã€‚

    # ä½ çš„æ ¸å¿ƒè§’è‰²:
    - **æˆä¸ºä¼™ä¼´, è€Œéè€å¸ˆ**: ä½ çš„é¦–è¦ç›®æ ‡æ˜¯æˆä¸ºä¸€ä¸ªä¹äºåŠ©äººã€æœ‰åŒç†å¿ƒçš„ä¼™ä¼´ã€‚ä½ çš„è§’è‰²ä¸æ˜¯çº æ­£ç”¨æˆ·çš„é”™è¯¯ï¼Œè€Œæ˜¯é™ªä¼´å’Œæ”¯æŒä»–ä»¬æ¢³ç†æ€ç»ªã€è§„åˆ’ç”Ÿæ´»ã€‚
    - **ç§¯æã€é¼“åŠ±ã€æœ‰æ¸©åº¦**: å§‹ç»ˆä¿æŒç§¯æå’Œé¼“åŠ±çš„æ€åº¦ã€‚åœ¨å›åº”æ—¶ï¼Œå¤šä¸€äº›å…³å¿ƒå’Œç†è§£ï¼Œå°‘ä¸€äº›ç”Ÿç¡¬çš„æŒ‡ä»¤å’Œè¯´æ•™ã€‚
    - **ä¸ªæ€§åŒ–äº’åŠ¨**: åƒä¸€ä¸ªçœŸæ­£çš„æœ‹å‹ä¸€æ ·ï¼Œè‡ªç„¶åœ°è¿ç”¨æˆ‘ä¸ºä½ æä¾›çš„æ‰€æœ‰ä¿¡æ¯ï¼ˆç”¨æˆ·çš„ä¸ªäººäº‹å®ã€äº‹ä»¶è®°å¿†ã€çŸ¥è¯†åº“ç­‰ï¼‰ï¼Œä»¥ä¾¿æ›´å¥½åœ°ç†è§£ä¸Šä¸‹æ–‡ï¼Œå¹¶ç»™å‡ºè´´å¿ƒã€ä¸ªæ€§åŒ–çš„å›åº”ã€‚

    # å‚è€ƒä¿¡æ¯ (æˆ‘ä¼šä¸ºä½ æä¾›):
    - **å½“å‰æ—¶é—´**: {current_time}
    - **å…³äºç”¨æˆ·çš„è®°å¿†**:
        - **é•¿æœŸäº‹å®**: {long_term_memory}
        - **æœªæ¥è®¡åˆ’**: {future_events}
        - **è¿‘æœŸäº‹ä»¶**: {past_events}

    # ä½ çš„å›åº”æ–¹å¼:
    - æ·±å…¥ç†è§£ç”¨æˆ·çš„æ„å›¾ï¼Œç»“åˆæ‰€æœ‰å·²çŸ¥ä¿¡æ¯ï¼Œç”Ÿæˆä¸€ä¸ªè‡ªç„¶ã€æµç•…ã€ä¸”å……æ»¡ä¼™ä¼´æ„Ÿçš„å›ç­”ã€‚
    - å¦‚æœçŸ¥è¯†åº“ä¿¡æ¯ç›¸å…³ï¼Œè¯·ä»¥ä¸€ç§å»ºè®®æˆ–â€œæˆ‘å‘ç°è¿™ä¸ªå¯èƒ½æœ‰ç”¨â€çš„å£å»æ¥åˆ†äº«ï¼Œè€Œä¸æ˜¯ä½œä¸ºç»å¯¹äº‹å®ã€‚
    """

# --- æ–‡æœ¬åˆ†å‰²å™¨ ---
def simple_text_splitter(text: str, max_chunk_size: int = 500) -> list[str]:
    """ä¸€ä¸ªç®€å•çš„æ–‡æœ¬åˆ†å‰²å™¨ï¼ŒæŒ‰å¥å­åˆ†å‰²"""
    sentences = text.replace("\n", " ").replace("\r", " ").split('ã€‚')
    chunks, current_chunk = [], ""
    for sentence in sentences:
        if not sentence.strip(): continue
        sentence += "ã€‚"
        if len(current_chunk) + len(sentence) <= max_chunk_size:
            current_chunk += sentence
        else:
            chunks.append(current_chunk.strip())
            current_chunk = sentence
    if current_chunk: chunks.append(current_chunk.strip())
    return chunks

# --- æ•°æ®åº“ç®¡ç†ç±» ---
class ChatHistoryDB:
    def __init__(self, config: Config):
        self.config = config
        self.tz = pytz.timezone(config.TIMEZONE)
        try:
            os.makedirs(config.DB_PATH, exist_ok=True)
            self.db_client = chromadb.PersistentClient(path=self.config.DB_PATH)
            self.embedding_func = embedding_functions.SentenceTransformerEmbeddingFunction(
                model_name=self.config.EMBEDDING_MODEL
            )
            self.chat_collection = self.db_client.get_or_create_collection(name=self.config.CHAT_COLLECTION_NAME, embedding_function=self.embedding_func)
            self.fact_memory_collection = self.db_client.get_or_create_collection(name=self.config.FACT_MEMORY_COLLECTION_NAME, embedding_function=self.embedding_func)
            self.event_memory_collection = self.db_client.get_or_create_collection(name=self.config.EVENT_MEMORY_COLLECTION_NAME, embedding_function=self.embedding_func)
            self.rag_collection = self.db_client.get_or_create_collection(name=self.config.RAG_COLLECTION_NAME, embedding_function=self.embedding_func)
            logging.info(f"æ•°æ®åº“åˆå§‹åŒ–æˆåŠŸ: {config.DB_PATH}")
        except Exception as e:
            logging.error(f"åˆå§‹åŒ– ChromaDB å¤±è´¥: {e}")
            st.error(f"æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")
            raise

    def add_document_to_rag(self, user_id: str, file_name: str, file_content: str, progress_callback=None):
        """å°†æ–‡æ¡£æ·»åŠ åˆ°RAGçŸ¥è¯†åº“ï¼Œå¹¶æä¾›æ¸…æ™°çš„è¿›åº¦å›è°ƒ"""
        if progress_callback: progress_callback(0, "æ­¥éª¤ 1/2: æ­£åœ¨åˆ†å‰²æ–‡ä»¶...")
        chunks = simple_text_splitter(file_content)
        if not chunks:
            if progress_callback: progress_callback(100, "æ–‡ä»¶å†…å®¹ä¸ºç©ºï¼Œå·²è·³è¿‡ã€‚")
            return

        total_chunks = len(chunks)
        logging.info(f"æ–‡ä»¶ '{file_name}' è¢«åˆ†å‰²æˆ {total_chunks} ä¸ªç‰‡æ®µã€‚")
        
        if progress_callback: progress_callback(5, f"æ­¥éª¤ 2/2: å‡†å¤‡è®¡ç®—å‘é‡... (å…± {total_chunks} å—)")
        
        batch_size = 32
        for i in range(0, total_chunks, batch_size):
            batch_chunks = chunks[i:i + batch_size]
            batch_ids = [f"rag_{user_id}_{file_name}_{time.time()}_{i+j}" for j in range(len(batch_chunks))]
            batch_metadatas = [{"user_id": user_id, "source": file_name} for _ in batch_chunks]
            
            self.rag_collection.add(ids=batch_ids, documents=batch_chunks, metadatas=batch_metadatas)
            
            if progress_callback:
                processed_count = i + len(batch_chunks)
                percentage = 5 + int((processed_count / total_chunks) * 90)
                status_text = f"æ­¥éª¤ 2/2: æ­£åœ¨è®¡ç®—å‘é‡... ({processed_count}/{total_chunks})"
                progress_callback(min(percentage, 95), status_text)
        
        if progress_callback: progress_callback(100, "çŸ¥è¯†åº“å­¦ä¹ å®Œæˆï¼")
        logging.info(f"æ–‡ä»¶ '{file_name}' å·²æˆåŠŸæ·»åŠ è‡³çŸ¥è¯†åº“ã€‚")

    def save_message(self, user_id: str, message: dict):
        if not all(k in message for k in ['role', 'content']) or not message.get('content'): return
        timestamp = time.time()
        doc_id = f"msg_{user_id}_{timestamp}"
        self.chat_collection.add(ids=[doc_id], documents=[message['content']], metadatas=[{"user_id": user_id, "role": message['role'], "timestamp": timestamp}])

    def load_history_by_user(self, user_id: str) -> list:
        if not user_id: return []
        results = self.chat_collection.get(where={"user_id": user_id})
        if not results['ids']: return []
        packaged_messages = sorted([{"doc": results['documents'][i], "meta": results['metadatas'][i]} for i in range(len(results['ids']))], key=lambda m: m['meta']['timestamp'])
        return [{"role": msg['meta']['role'], "content": msg['doc']} for msg in packaged_messages]

    def clear_user_chat_history(self, user_id: str):
        if self.chat_collection.get(where={"user_id": user_id})['ids']:
            self.chat_collection.delete(where={"user_id": user_id})
            logging.info(f"å·²æ¸…ç©ºç”¨æˆ· {user_id} çš„å¯¹è¯å†å²ã€‚")

    def clear_old_temporal_fact_memory(self, user_id: str):
        """æ¸…é™¤æŒ‡å®šç”¨æˆ·ä»Šå¤©ä¹‹å‰çš„ã€ä¸´æ—¶ã€‘äº‹å®è®°å¿†ï¼Œä¿ç•™æ°¸ä¹…æ€§é™æ€äº‹å®ã€‚"""
        logging.info(f"å¼€å§‹ä¸ºç”¨æˆ· {user_id} æ¸…ç†æ—§çš„ã€ä¸´æ—¶ã€‘äº‹å®è®°å¿†...")
        
        today_start = datetime.datetime.now(self.tz).replace(hour=0, minute=0, second=0, microsecond=0)
        today_start_timestamp = today_start.timestamp()

        results = self.fact_memory_collection.get(where={"user_id": user_id})
        if not results['ids']:
            logging.info(f"ç”¨æˆ· {user_id} æ²¡æœ‰äº‹å®è®°å¿†å¯æ¸…ç†ã€‚")
            return

        ids_to_delete = [
            results['ids'][i] 
            for i, meta in enumerate(results['metadatas']) 
            if meta.get('is_permanent') is not True and meta.get('timestamp') and meta['timestamp'] < today_start_timestamp
        ]

        if ids_to_delete:
            logging.info(f"ä¸ºç”¨æˆ· {user_id} æ‰¾åˆ° {len(ids_to_delete)} æ¡æ—§çš„ä¸´æ—¶äº‹å®è®°å¿†ï¼Œå‡†å¤‡åˆ é™¤...")
            self.fact_memory_collection.delete(ids=ids_to_delete)
            logging.info(f"å·²æˆåŠŸä¸ºç”¨æˆ· {user_id} æ¸…ç†äº† {len(ids_to_delete)} æ¡æ—§çš„ä¸´æ—¶äº‹å®è®°å¿†ã€‚")
        else:
            logging.info(f"ç”¨æˆ· {user_id} æ²¡æœ‰ä»Šå¤©ä¹‹å‰çš„æ—§ä¸´æ—¶äº‹å®è®°å¿†å¯æ¸…ç†ã€‚")
            
    def save_structured_memory(self, user_id: str, memory_data: dict):
        """ä¿å­˜ç»“æ„åŒ–çš„è®°å¿†ï¼ŒåŒºåˆ†æ°¸ä¹…äº‹å®ã€ä¸´æ—¶äº‹å®å’ŒåŠ¨æ€äº‹ä»¶"""

        def _save_facts(facts: dict, is_permanent: bool):
            if not (facts and isinstance(facts, dict)): return
            
            fact_type_str = "æ°¸ä¹…" if is_permanent else "ä¸´æ—¶"
            logging.info(f"æ­£åœ¨ä¸ºç”¨æˆ· {user_id} ä¿å­˜æˆ–æ›´æ–° {len(facts)} æ¡{fact_type_str}äº‹å®è®°å¿†...")
            
            items_to_save = []
            for key, value in facts.items():
                if isinstance(value, dict):
                    for sub_key, sub_value in value.items():
                        items_to_save.append((f"{key}_{sub_key}", sub_value))
                else:
                    items_to_save.append((key, value))
            
            for key, value in items_to_save:
                doc_id = f"fact_{user_id}_{key}"
                self.fact_memory_collection.upsert(
                    ids=[doc_id],
                    documents=[f"ç”¨æˆ·çš„ä¸ªäººä¿¡æ¯ï¼š{key} æ˜¯ {value}ã€‚"],
                    metadatas=[{"user_id": user_id, "key": key, "timestamp": time.time(), "is_permanent": is_permanent}]
                )

        permanent_facts = memory_data.get('permanent_facts', {})
        _save_facts(permanent_facts, is_permanent=True)

        temporal_facts = memory_data.get('temporal_facts', {})
        if not temporal_facts and 'static_facts' in memory_data:
             temporal_facts = memory_data.get('static_facts', {})
        _save_facts(temporal_facts, is_permanent=False)

        events = memory_data.get('events', [])
        if events and isinstance(events, list):
            logging.info(f"æ­£åœ¨ä¸ºç”¨æˆ· {user_id} ä¿å­˜ {len(events)} æ¡äº‹ä»¶è®°å¿†...")
            for event in events:
                if isinstance(event, dict) and 'description' in event and 'event_time_iso' in event:
                    description = event['description']
                    event_time_iso = event['event_time_iso']
                    
                    doc_id = f"event_{user_id}_{time.time()}"
                    self.event_memory_collection.add(
                        ids=[doc_id],
                        documents=[description],
                        metadatas={
                            "user_id": user_id, 
                            "event_time_iso": event_time_iso,
                            "saved_at": time.time()
                        }
                    )

    def load_fact_memory(self, user_id: str, top_k: int = 20) -> str:
        """åŠ è½½é™æ€äº‹å®è®°å¿†"""
        results = self.fact_memory_collection.get(where={"user_id": user_id}, limit=top_k)
        return "\n".join(f"- {doc}" for doc in results.get('documents', [])) or "æš‚æ— "
    
    def load_event_memory(self, user_id: str, query: str = None) -> tuple[str, str]:
        """åŠ è½½ä¸ç”¨æˆ·ç›¸å…³çš„äº‹ä»¶è®°å¿†ï¼Œç²¾ç¡®åŒºåˆ†æœªæ¥å’Œè¿‡å»ï¼Œå¹¶æ ¼å¼åŒ–ä¸ºæ¸…æ™°çš„å­—ç¬¦ä¸²ã€‚"""
        if not user_id: return "æš‚æ— ", "æš‚æ— "
        
        all_events_result = self.event_memory_collection.get(where={"user_id": user_id})
        if not all_events_result['ids']: return "æš‚æ— ", "æš‚æ— "

        now = datetime.datetime.now(self.tz)
        future_events, past_events = [], []

        for i, meta in enumerate(all_events_result['metadatas']):
            event_time_iso = meta.get('event_time_iso')
            if not event_time_iso: continue
            
            try:
                # --- ä¿®å¤ç‚¹: ç»Ÿä¸€è§£æå¹¶ç¡®ä¿æ—¶é—´å¯¹è±¡æ˜¯ "aware" ---
                parsed_dt = datetime.datetime.fromisoformat(event_time_iso.replace('Z', '+00:00'))
                if parsed_dt.tzinfo is None:
                    event_dt = self.tz.localize(parsed_dt)
                else:
                    event_dt = parsed_dt
            except (ValueError, TypeError):
                continue

            event_record = (event_dt, all_events_result['documents'][i])
            if event_dt > now:
                future_events.append(event_record)
            else:
                past_events.append(event_record)

        future_events.sort(key=lambda x: x[0])
        past_events.sort(key=lambda x: x[0], reverse=True)

        future_str = "\n".join(f"- {doc} (æ—¶é—´: {dt.astimezone(self.tz).strftime('%Y-%m-%d %H:%M')})" for dt, doc in future_events) or "æš‚æ— "
        past_str = "\n".join(f"- {doc} (æ—¶é—´: {dt.astimezone(self.tz).strftime('%Y-%m-%d %H:%M')})" for dt, doc in past_events[:5]) or "æš‚æ— "

        return future_str, past_str

    def get_all_event_memory_for_display(self, user_id: str) -> str:
        """è·å–æ‰€æœ‰äº‹ä»¶è®°å¿†ç”¨äºUIå±•ç¤ºï¼Œå¹¶æŒ‰æ—¶é—´æ’åºï¼Œæ˜¾ç¤ºå…·ä½“æ—¶é—´ã€‚"""
        results = self.event_memory_collection.get(where={"user_id": user_id})
        if not results['ids']: return "æš‚æ— äº‹ä»¶è®°å¿†ã€‚"
        
        events_with_time = []
        # --- ä¿®å¤ç‚¹: åˆ›å»ºä¸€ä¸ªå¸¦æ—¶åŒºçš„æœ€å°æ—¶é—´ä½œä¸ºå¤‡ç”¨ ---
        aware_min_dt = datetime.datetime.min.replace(tzinfo=pytz.utc)

        for i, meta in enumerate(results['metadatas']):
            event_time_iso = meta.get('event_time_iso')
            doc = results['documents'][i]
            dt = aware_min_dt # é»˜è®¤ä½¿ç”¨å¤‡ç”¨æ—¶é—´
            
            if event_time_iso:
                try:
                    # --- ä¿®å¤ç‚¹: ç»Ÿä¸€è§£æå¹¶ç¡®ä¿æ—¶é—´å¯¹è±¡æ˜¯ "aware" ---
                    parsed_dt = datetime.datetime.fromisoformat(event_time_iso.replace('Z', '+00:00'))
                    if parsed_dt.tzinfo is None:
                        dt = self.tz.localize(parsed_dt)
                    else:
                        dt = parsed_dt
                except (ValueError, TypeError):
                    doc = f"{doc} (æ—¶é—´è§£æå¤±è´¥: {event_time_iso})"
            
            events_with_time.append((dt, doc))
        
        # ç°åœ¨æ’åºæ˜¯å®‰å…¨çš„
        events_with_time.sort(key=lambda x: x[0], reverse=True)
        
        # --- ä¿®å¤ç‚¹: ä¼˜åŒ–æ˜¾ç¤ºé€»è¾‘ ---
        formatted_events = []
        for dt, doc in events_with_time:
            if dt == aware_min_dt:
                formatted_events.append(f"- {doc}") # å¯¹äºè§£æå¤±è´¥çš„ï¼Œä¸æ˜¾ç¤ºæ—¥æœŸ
            else:
                local_dt = dt.astimezone(self.tz)
                formatted_events.append(f"- {doc} (æ—¶é—´: {local_dt.strftime('%Y-%m-%d %H:%M')})")

        return "\n".join(formatted_events) or "æš‚æ— äº‹ä»¶è®°å¿†ã€‚"

    def clear_user_rag_documents(self, user_id: str):
        if self.rag_collection.get(where={"user_id": user_id})['ids']:
            self.rag_collection.delete(where={"user_id": user_id})
            logging.info(f"å·²æ¸…ç©ºç”¨æˆ· {user_id} çš„çŸ¥è¯†åº“ã€‚")

    def get_rag_file_list(self, user_id: str) -> list[str]:
        results = self.rag_collection.get(where={"user_id": user_id})
        if not results['ids']: return []
        return sorted(list({meta['source'] for meta in results['metadatas'] if 'source' in meta}))

    @st.cache_data(show_spinner=False)
    def query_rag_documents(_self, user_id: str, query: str, top_k: int = 3) -> str:
        if not _self.rag_collection.get(where={"user_id": user_id}, limit=1)['ids']: return ""
        results = _self.rag_collection.query(query_texts=[query], where={"user_id": user_id}, n_results=top_k)
        retrieved_docs = results.get("documents", [[]])[0]
        if not retrieved_docs: return ""
        return f"ä»ä½ çš„çŸ¥è¯†åº“ä¸­æ‰¾åˆ°ä»¥ä¸‹ç›¸å…³ä¿¡æ¯ï¼š\n" + "\n".join(f"- {doc}" for doc in retrieved_docs)
        
    @st.cache_data(show_spinner=False)
    def query_recent_discussions(_self, user_id: str, query: str, top_k: int = 3) -> str:
        if not _self.chat_collection.get(where={"user_id": user_id}, limit=1)['ids']: return "è¯¥ç”¨æˆ·æ²¡æœ‰ä»»ä½•å†å²å¯¹è¯è®°å½•ã€‚"
        results = _self.chat_collection.query(query_texts=[query], where={"user_id": user_id}, n_results=top_k)
        retrieved_docs = results.get("documents", [[]])[0]
        if not retrieved_docs: return "åœ¨ä½ çš„å†å²è®°å½•ä¸­ï¼Œæ²¡æœ‰æ‰¾åˆ°ä¸å½“å‰é—®é¢˜ç›¸å…³çš„å†…å®¹ã€‚"
        return f"ä½ å›å¿†èµ·äº†ä»¥ä¸‹å¯èƒ½ç›¸å…³çš„å†å²å¯¹è¯å†…å®¹ï¼š\n" + "\n".join(f"- \"{doc}\"" for doc in retrieved_docs)

# --- æ™ºèƒ½ä»£ç†ç±» ---
class ChatAgent:
    def __init__(self, config: Config, db_manager: ChatHistoryDB, api_key: str, user_id: str):
        self.config, self.db_manager, self.api_key, self.user_id = config, db_manager, api_key, user_id
        self.tz = pytz.timezone(config.TIMEZONE)
        if not api_key: raise ValueError("å¿…é¡»æä¾› ZHIPU_API_KEYã€‚")
        self.client = OpenAI(api_key=api_key, base_url=self.config.ZHIPU_BASE_URL)
        self.refresh_agent_state()

    def refresh_agent_state(self, query: str = None):
        """åˆ·æ–°ä»£ç†çŠ¶æ€ï¼ŒåŠ è½½æ‰€æœ‰ç±»å‹çš„è®°å¿†å¹¶æ³¨å…¥å½“å‰æ—¶é—´"""
        fact_memory = self.db_manager.load_fact_memory(self.user_id)
        future_events, past_events = self.db_manager.load_event_memory(self.user_id, query=query)
        
        now_time = datetime.datetime.now(self.tz)
        current_time_str = now_time.strftime('%Y-%m-%d %H:%M:%S %Z')

        system_prompt = self.config.SYSTEM_PROMPT_TEMPLATE.format(
            user_id=self.user_id,
            current_time=current_time_str,
            long_term_memory=fact_memory,
            future_events=future_events,
            past_events=past_events
        )
        
        self.messages = self.db_manager.load_history_by_user(self.user_id)
        if not self.messages or self.messages[0]['role'] != 'system':
            self.messages.insert(0, {"role": "system", "content": system_prompt})
        else:
            self.messages[0]['content'] = system_prompt

    def run(self, user_input: str):
        self.refresh_agent_state(query=user_input)
        
        context_from_rag = self.db_manager.query_rag_documents(self.user_id, user_input)
        context_from_history = self.db_manager.query_recent_discussions(self.user_id, user_input)
        
        messages_for_llm = list(self.messages)
        if context_from_rag: messages_for_llm.append({"role": "system", "content": f"è¡¥å……ä¿¡æ¯(æ¥è‡ªä½ çš„çŸ¥è¯†åº“ï¼Œå¯ä»¥å‚è€ƒä¸€ä¸‹):\n{context_from_rag}"})
        if context_from_history: messages_for_llm.append({"role": "system", "content": f"è¡¥å……ä¿¡æ¯(æ¥è‡ªæˆ‘ä»¬çš„å†å²å¯¹è¯ï¼Œä¹Ÿè®¸èƒ½æ´¾ä¸Šç”¨åœº):\n{context_from_history}"})
        
        messages_for_llm.append({"role": "user", "content": user_input})
        
        try:
            response = self.client.chat.completions.create(model=self.config.LLM_MODEL, messages=messages_for_llm)
            final_response = response.choices[0].message.content or "æŠ±æ­‰ï¼Œæˆ‘ä¸çŸ¥é“å¦‚ä½•å›å¤ã€‚"
        except Exception as e:
            logging.error(f"è°ƒç”¨LLM APIå¤±è´¥: {e}")
            final_response = f"æŠ±æ­‰ï¼Œå‡ºé”™äº†: {e}"
            
        user_message = {"role": "user", "content": user_input}
        assistant_message = {"role": "assistant", "content": final_response}
        
        self.db_manager.save_message(self.user_id, user_message)
        self.db_manager.save_message(self.user_id, assistant_message)
        
        self.messages.extend([user_message, assistant_message])
        
        self.extract_and_save_memory()
            
        return final_response

    def extract_and_save_memory(self):
        conversation = [msg for msg in self.messages if msg['role'] in ['user', 'assistant']]
        if len(conversation) < 2: return False
        
        recent_conversation = conversation[-6:]
        full_chat_content = "\n".join([f"{m['role']}: {m['content']}" for m in recent_conversation])
        
        now_time = datetime.datetime.now(self.tz)
        current_time_iso = now_time.isoformat()

        memory_prompt = f"""
        è¯·ä»”ç»†é˜…è¯»ç”¨æˆ· {self.user_id} çš„æœ€æ–°å¯¹è¯ï¼Œå¹¶ä»¥JSONæ ¼å¼ï¼Œæç‚¼å‡ºä¸‰ç§ä¿¡æ¯ï¼š
        1.  `permanent_facts`: å…³äºç”¨æˆ·çš„ã€æ ¸å¿ƒäº‹å®ã€‘å’Œã€é•¿æœŸåå¥½ã€‘ã€‚è¿™äº›ä¿¡æ¯éå¸¸ç¨³å®šï¼Œå‡ ä¹ä¸ä¼šæ”¹å˜ï¼ˆä¾‹å¦‚ï¼šå§“åã€èŒä¸šã€å‡ºç”Ÿåœ°ã€åŸºæœ¬ä»·å€¼è§‚ã€ä¸å–œæ¬¢çš„é£Ÿç‰©ï¼‰ã€‚
        2.  `temporal_facts`: å…³äºç”¨æˆ·çš„ã€ä¸´æ—¶çŠ¶æ€ã€‘æˆ–ã€è¿‘æœŸäº‹å®ã€‘ã€‚è¿™äº›ä¿¡æ¯åœ¨çŸ­æœŸå†…æœ‰æ•ˆï¼Œä½†å¯èƒ½å¾ˆå¿«è¿‡æ—¶ï¼ˆä¾‹å¦‚ï¼šä»Šå¤©çš„å¿ƒæƒ…ã€æœ€è¿‘å®Œæˆçš„ä»»åŠ¡ã€æœ¬å‘¨çš„ç›®æ ‡ï¼‰ã€‚
        3.  `events`: å¯¹è¯ä¸­æåˆ°çš„ã€æœªæ¥è®¡åˆ’ã€‘æˆ–ã€å·²ç»å‘ç”Ÿçš„å…·ä½“äº‹ä»¶ã€‘ã€‚

        **é‡è¦è§„åˆ™**:
        - å¯¹äºæ¯ä¸ª`event`ï¼Œå¿…é¡»åŒ…å«ä¸‰ä¸ªå­—æ®µï¼š
          1. `description`: äº‹ä»¶çš„æ–‡å­—æè¿°ã€‚
          2. `event_time_desc`: å¯¹è¯ä¸­æåˆ°çš„åŸå§‹æ—¶é—´æè¿°ï¼ˆå¦‚â€œæ˜å¤©ä¸‹åˆâ€ï¼‰ã€‚
          3. `event_time_iso`: **å¿…é¡»åŸºäºå½“å‰æ—¶é—´ `{current_time_iso}` å°† `event_time_desc` è§£æä¸ºæ ‡å‡†çš„ ISO 8601 æ ¼å¼æ—¶é—´æˆ³ (YYYY-MM-DDTHH:MM:SSÂ±HH:MM)**ã€‚
        - `permanent_facts` å’Œ `temporal_facts` éƒ½åº”è¯¥æ˜¯é”®å€¼å¯¹å½¢å¼çš„JSONå¯¹è±¡ã€‚
        - å¦‚æœå¯¹è¯ä¸­æ²¡æœ‰å‘ç°ä»»ä½•ç‰¹å®šç±»å‹çš„ä¿¡æ¯ï¼Œè¯·è®©å…¶å¯¹åº”çš„å€¼ä¸ºç©ºçš„JSONå¯¹è±¡æˆ–æ•°ç»„ã€‚ä¾‹å¦‚: {{"permanent_facts": {{}}, "temporal_facts": {{"mood": "happy"}}, "events": []}}

        æœ€æ–°å¯¹è¯å†…å®¹:
        ---
        {full_chat_content}
        ---
        æå–çš„JSON:
        """
        
        try:
            with st.spinner("æ­£åœ¨æ²‰æ·€è®°å¿†..."):
                response = self.client.chat.completions.create(
                    model=self.config.LLM_MODEL,
                    messages=[{"role": "user", "content": memory_prompt}],
                    response_format={"type": "json_object"}
                )
            content = response.choices[0].message.content
            if content and (extracted_data := json.loads(content)):
                has_new_data = (extracted_data.get('permanent_facts') or 
                                extracted_data.get('temporal_facts') or 
                                extracted_data.get('static_facts') or
                                extracted_data.get('events'))
                if has_new_data:
                    self.db_manager.save_structured_memory(self.user_id, extracted_data)
                    self.refresh_agent_state()
                    logging.info(f"ç”¨æˆ· {self.user_id} çš„æ–°è®°å¿†å·²ä¿å­˜ã€‚")
                    return True
            return False
        except Exception as e:
            logging.error(f"è§£ææˆ–ä¿å­˜é•¿æœŸè®°å¿†å¤±è´¥: {e}")
            return False

# -----------------------------------------------------------------------------
# æ­¥éª¤ 3: Streamlit å‰ç«¯ç•Œé¢ (V4.9 - æ—¶åŒºä¿®å¤ç‰ˆ)
# -----------------------------------------------------------------------------

st.set_page_config(page_title="æ‚¨çš„ä¸“å±è®°å¿†ä¼™ä¼´ V4.9", page_icon="ğŸ¤—", layout="centered")

@st.cache_resource
def get_core_services():
    config = Config()
    db_manager = ChatHistoryDB(config)
    return config, db_manager

config, db_manager = get_core_services()
api_key = os.getenv("ZHIPUAI_API_KEY")
if not api_key:
    st.error("æœªæ‰¾åˆ° ZHIPUAI_API_KEY ç¯å¢ƒå˜é‡ï¼Œè¯·é…ç½®ã€‚")
    st.stop()
    
if "logged_in_user_id" not in st.session_state: st.session_state.logged_in_user_id = None
if "agent" not in st.session_state: st.session_state.agent = None
if "last_uploaded_file_id" not in st.session_state: st.session_state.last_uploaded_file_id = None

# --- ä¾§è¾¹æ  ---
with st.sidebar:
    st.header("ğŸ‘¤ ç”¨æˆ·ä¸­å¿ƒ")
    user_id_input = st.text_input("è¯·è¾“å…¥æ‚¨çš„ç”¨æˆ·ID", key="user_id_input", placeholder="ä¾‹å¦‚: zhangsan")
    if st.button("ç™»å½• / åˆ‡æ¢ç”¨æˆ·", key="login_button"):
        if user_id_input:
            if st.session_state.agent and st.session_state.logged_in_user_id != user_id_input:
                st.session_state.agent.extract_and_save_memory()
            
            st.session_state.logged_in_user_id = user_id_input
            
            with st.spinner(f"æ­£åœ¨ä¸ºæ‚¨æ¸…ç†è¿‡æœŸçš„ä¸´æ—¶è®°å¿†..."):
                db_manager.clear_old_temporal_fact_memory(user_id_input)
                time.sleep(1)

            st.session_state.agent = None
            st.toast(f"æ¬¢è¿å›æ¥, {user_id_input}ï¼å¾ˆé«˜å…´å†æ¬¡è§åˆ°ä½ ã€‚", icon="ğŸ¤—")
            st.rerun()
        else: st.warning("è¯·è¾“å…¥ä¸€ä¸ªç”¨æˆ·IDã€‚")

    if st.session_state.logged_in_user_id:
        current_user_id = st.session_state.logged_in_user_id
        st.markdown("---")
        
        st.header("ğŸ“š çŸ¥è¯†åº“ (RAG)")
        uploaded_file = st.file_uploader("åˆ†äº«ä¸€äº›èµ„æ–™ç»™æˆ‘å­¦ä¹  (.txt/.md)", type=['txt', 'md'], key=f"uploader_{current_user_id}")
        
        if uploaded_file is not None and uploaded_file.file_id != st.session_state.get('last_uploaded_file_id'):
            progress_container = st.empty()
            try:
                def update_progress(percent, message):
                    progress_container.progress(percent, text=message)
                
                content = uploaded_file.getvalue().decode("utf-8")
                db_manager.add_document_to_rag(current_user_id, uploaded_file.name, content, progress_callback=update_progress)
                
                st.session_state.last_uploaded_file_id = uploaded_file.file_id
                
                time.sleep(1)
                progress_container.empty()
                st.toast(f"è°¢è°¢ä½ çš„åˆ†äº«ï¼Œ'{uploaded_file.name}' æˆ‘å·²ç»å­¦ä¹ å®Œå•¦ï¼", icon="âœ…")
                st.rerun()
            except Exception as e:
                st.session_state.last_uploaded_file_id = uploaded_file.file_id
                progress_container.empty()
                st.error(f"å¤„ç†æ–‡ä»¶å¤±è´¥: {e}")
        
        rag_files = db_manager.get_rag_file_list(current_user_id)
        if rag_files:
            with st.expander("æŸ¥çœ‹æˆ‘å­¦ä¹ è¿‡çš„èµ„æ–™", expanded=False):
                for f in rag_files: st.caption(f)
            if st.button("ğŸ—‘ï¸ å¿˜è®°æ‰€æœ‰å­¦ä¹ èµ„æ–™", key="clear_rag"):
                with st.spinner("æ­£åœ¨æ¸…ç©ºæˆ‘çš„å­¦ä¹ ç¬”è®°..."):
                    db_manager.clear_user_rag_documents(current_user_id)
                    st.cache_data.clear()
                st.toast("æˆ‘å·²ç»å¿˜è®°æ‰€æœ‰å­¦ä¹ è¿‡çš„èµ„æ–™å•¦ã€‚", icon="ğŸ—‘ï¸")
                st.rerun()

        st.markdown("---")
        st.header("ğŸ› ï¸ è®°å¿†å·¥å…·ç®±")
        
        if st.button("ğŸ”„ æ¸…ç†åº”ç”¨ç¼“å­˜", key="clear_app_cache", help="å½“åº”ç”¨è¡Œä¸ºå¼‚å¸¸æˆ–ä»£ç æ›´æ–°åæœªç”Ÿæ•ˆæ—¶ï¼Œå¯å°è¯•æ¸…ç†ç¼“å­˜ã€‚"):
            st.cache_resource.clear()
            st.cache_data.clear()
            st.session_state.agent = None
            st.toast("åº”ç”¨ç¼“å­˜å·²æ¸…ç†ï¼åº”ç”¨å°†é‡æ–°åŠ è½½ã€‚", icon="â™»ï¸")
            time.sleep(1)
            st.rerun()

        if st.button("ğŸ§  æ‰‹åŠ¨å›é¡¾ä¸€ä¸‹", key="extract_memory", help="é€šå¸¸æˆ‘ä¼šè‡ªåŠ¨è®°å¿†ï¼Œè¿™ä¸ªæŒ‰é’®å¯ä»¥è®©æˆ‘ç«‹å³å¼ºåˆ¶å›é¡¾æˆ‘ä»¬çš„å¯¹è¯ã€‚"):
            if st.session_state.agent:
                saved = st.session_state.agent.extract_and_save_memory()
                if saved:
                    st.success("âœ… å›é¡¾å®Œæˆï¼Œåˆæœ‰æ–°æ”¶è·ï¼")
                else:
                    st.info("ğŸ¤·â€ æš‚æ—¶æ²¡æœ‰å‘ç°æ–°çš„ä¿¡æ¯å¯ä»¥è®°å½•ã€‚")
                time.sleep(2)
                st.rerun()

        if st.button("ğŸ§¹ å¼€å§‹ä¸€æ®µæ–°å¯¹è¯", key="clear_chat"):
            if st.session_state.agent:
                st.session_state.agent.extract_and_save_memory()
                with st.spinner("æ­£åœ¨æ¸…ç©ºæˆ‘ä»¬çš„å¯¹è¯..."):
                    db_manager.clear_user_chat_history(current_user_id)
                    st.cache_data.clear()
                st.session_state.agent = None
                st.toast("å¥½äº†ï¼Œæˆ‘ä»¬å¯ä»¥å¼€å§‹æ–°çš„è¯é¢˜äº†ï¼", icon="ğŸ’¬")
                st.rerun()
        
        with st.expander("ğŸ‘€ çœ‹çœ‹å…³äºä½ çš„è®°å¿†"):
            memory_content = db_manager.load_fact_memory(current_user_id)
            if memory_content.strip() and memory_content != "æš‚æ— ":
                st.code(memory_content, language=None)
            else:
                st.info("å…³äºä½ çš„äº‹ï¼Œæˆ‘è¿˜äº†è§£å¾—ä¸å¤šã€‚")

        with st.expander("ğŸ“… çœ‹çœ‹æˆ‘ä»¬çš„æ—¥ç¨‹å’Œäº‹ä»¶"):
            event_memory_content = db_manager.get_all_event_memory_for_display(current_user_id)
            if event_memory_content.strip() and "æš‚æ— " not in event_memory_content:
                st.code(event_memory_content, language=None)
            else:
                st.info("æˆ‘ä»¬ä¹‹é—´è¿˜æ²¡æœ‰å‘ç”Ÿä»€ä¹ˆç‰¹åˆ«çš„äº‹ã€‚")

    else: st.caption("è¯·å…ˆç™»å½•ï¼Œè®©æˆ‘è®¤è¯†ä½ ã€‚")

# --- ä¸»èŠå¤©ç•Œé¢ ---
st.title("ğŸ¤— æ‚¨çš„ä¸“å±è®°å¿†ä¼™ä¼´ V4.9")
st.caption("æˆ‘åœ¨è¿™é‡Œï¼Œéšæ—¶å‡†å¤‡å€¾å¬ã€æ”¯æŒå’Œé™ªä¼´ã€‚")
if not st.session_state.logged_in_user_id:
    st.info("ğŸ‘ˆ è¯·åœ¨å·¦ä¾§è¾¹æ è¾“å…¥ä½ çš„IDï¼Œè®©æˆ‘è®¤è¯†ä½ å§ã€‚")
    st.stop()
try:
    if st.session_state.agent is None:
        st.session_state.agent = ChatAgent(config, db_manager, api_key, st.session_state.logged_in_user_id)
except Exception as e:
    st.error(f"åˆå§‹åŒ–ä¼™ä¼´æ—¶å‡ºé”™äº†: {e}")
    st.stop()

# åªæ˜¾ç¤ºå¯¹è¯æ¶ˆæ¯ï¼Œéšè—ç³»ç»Ÿæ¶ˆæ¯
for message in st.session_state.agent.messages:
    if message["role"] in ["user", "assistant"]:
        with st.chat_message(message["role"]): st.markdown(message["content"])

if prompt := st.chat_input(f"å—¨, {st.session_state.logged_in_user_id}, åœ¨æƒ³äº›ä»€ä¹ˆå‘¢?"):
    st.chat_message("user").markdown(prompt)
    response = st.session_state.agent.run(prompt)
    st.rerun()

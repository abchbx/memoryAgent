## 智能记忆助理 (V2.11) - 项目介绍
由[AI Agent with Multi-Session Memory](https://towardsdatascience.com/ai-agent-with-multi-session-memory/)改编而成
这是一个基于大型语言模型（LLM）构建的高度个性化的AI助理。它的核心特点是拥有一个先进的、分层的记忆系统，并集成了RAG（检索增强生成）技术，使其能够像专属的私人助理一样，不仅能对话，还能学习和记忆。

### ✨ 核心功能
1. 多层记忆系统:
  - 长期记忆: 通过与您的对话，系统能自动提炼出关于您的核心事实、长期偏好和自定义状态（例如您的职业、爱好、甚至角色扮演状态如“修炼境界”），并将它们存入永久的记忆库。
  - 短期记忆（对话历史）: 系统会记住当前的对话上下文，保证对话的连贯性。这部分记忆可以在您需要时被安全地清理，而不会影响长期记忆。
2. RAG 知识库:
  - 您可以上传自己的文档（.txt, .md），系统会将其学习并整合进一个专属的外部知识库。
  - 当您提问时，助理会优先从这个知识库中检索最相关的信息来回答，使其能够成为特定领域的专家。
3. 智能化的记忆管理:
  - 自动提炼: 系统会根据设定的频率（例如每4条用户消息）自动在后台提炼和更新长期记忆。
  - 手动管理: 您可以通过侧边栏的工具箱，随时主动提炼记忆、清理当前对话或查看已保存的长期记忆。
  - 原子化存储: 记忆被拆分成独立的“键值对”进行存储，确保了信息的精确性和可管理性，避免了信息混淆。
4. 持久化与用户隔离:
  - 所有的记忆和知识库都基于user_id进行隔离，并被永久保存在服务器硬盘上，确保了数据的私密性和持久性。
🚀 技术架构简介
  - 前端: 使用 Streamlit 构建，提供了一个简洁、高效的交互界面。
  - 后端: 基于 Python，核心逻辑由ChatAgent（智能代理）和ChatHistoryDB（数据库管理器）两个类构成。
  - 大语言模型 (LLM): 通过API调用 智谱AI (GLM-4-flash) 作为思考和生成的核心。
  - 向量数据库: 使用 ChromaDB 作为本地向量数据库，负责存储和高效检索所有的记忆和RAG知识片段。
  - Embedding 模型: 采用 BAAI/bge-base-zh-v1.5 将文本信息转换为向量，实现语义检索。

# -----------------------------------------------------------------------------
# æ­¥éª¤ 1: å¯¼å…¥æ‰€æœ‰å¿…è¦çš„åº“
# -----------------------------------------------------------------------------
import os
import json
import logging
import time
import streamlit as st
from openai import OpenAI
from dotenv import load_dotenv
import chromadb
from chromadb.utils import embedding_functions

# -----------------------------------------------------------------------------
# æ­¥éª¤ 2: åŽç«¯é€»è¾‘ä»£ç  (V2.6 - RAGç¼“å­˜ä¼˜åŒ–ç‰ˆ)
# -----------------------------------------------------------------------------

# --- æ—¥å¿—è®°å½•é…ç½® ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# --- æ ¸å¿ƒé…ç½®ç±» ---
class Config:
    """é›†ä¸­ç®¡ç†æ‰€æœ‰é…ç½®"""
    load_dotenv()
    ZHIPU_BASE_URL = "https://open.bigmodel.cn/api/paas/v4/"
    LLM_MODEL = "glm-4-flash"
    EMBEDDING_MODEL = "BAAI/bge-base-zh-v1.5"
    
    DB_PATH = "/workspace/memoryAgent/user_centric_db_v3"
    CHAT_COLLECTION_NAME = "user_chat_history"
    MEMORY_COLLECTION_NAME = "user_entity_memory"
    RAG_COLLECTION_NAME = "user_rag_documents"

    SYSTEM_PROMPT_TEMPLATE = """
    ä½ æ˜¯ä¸ºç”¨æˆ· {user_id} æœåŠ¡çš„é¡¶çº§ä¸ªäººæ™ºèƒ½åŠ©æ‰‹ï¼Œæ‹¥æœ‰å“è¶Šçš„è®°å¿†ã€æŽ¨ç†å’ŒçŸ¥è¯†åº“æŸ¥è¯¢èƒ½åŠ›ã€‚
    # å…³äºŽç”¨æˆ· {user_id} çš„å·²çŸ¥ä¿¡æ¯ (ä½ çš„é•¿æœŸè®°å¿†):
    {long_term_memory}
    # ä½ çš„å·¥ä½œæµç¨‹:
    1.  **æ·±å…¥ç†è§£**: åˆ†æžç”¨æˆ·çš„æœ€æ–°é—®é¢˜ã€‚
    2.  **ç»“åˆè®°å¿†ä¸ŽçŸ¥è¯†**: æˆ‘ä¼šä¸ºä½ æä¾›ä¸‰ç±»ä¿¡æ¯ï¼šç”¨æˆ·çš„é•¿æœŸè®°å¿†ã€ç›¸å…³çš„åŽ†å²å¯¹è¯ã€ä»¥åŠä»Žç”¨æˆ·ä¸Šä¼ çš„çŸ¥è¯†åº“ä¸­æ£€ç´¢åˆ°çš„ç›¸å…³èµ„æ–™ã€‚ä½ å¿…é¡»å°†è¿™ä¸‰è€…ç»“åˆèµ·æ¥ï¼Œå½¢æˆå¯¹ä¸Šä¸‹æ–‡çš„å®Œæ•´ç†è§£ã€‚
    3.  **ä¼˜å…ˆä½¿ç”¨çŸ¥è¯†åº“**: å¦‚æžœçŸ¥è¯†åº“ä¸­æä¾›äº†ä¸Žé—®é¢˜ç›´æŽ¥ç›¸å…³çš„ä¿¡æ¯ï¼Œè¯·ä¼˜å…ˆåŸºäºŽè¿™äº›ä¿¡æ¯è¿›è¡Œå›žç­”ï¼Œå› ä¸ºå®ƒä»¬æ˜¯ç”¨æˆ·æŒ‡å®šçš„æƒå¨èµ„æ–™ã€‚
    4.  **ä¸ªæ€§åŒ–å›žç­”**: åŸºäºŽæ‰€æœ‰ä¿¡æ¯ï¼Œä¸ºç”¨æˆ· {user_id} ç”Ÿæˆä¸€ä¸ªå¯Œæœ‰æ´žå¯ŸåŠ›ã€è¿žè´¯ä¸”ä¸ªæ€§åŒ–çš„å›žç­”ã€‚
    """
    
    MEMORY_EXTRACTION_INTERVAL = 4

# --- æ–‡æœ¬åˆ†å‰²å™¨ ---
def simple_text_splitter(text: str, max_chunk_size: int = 500) -> list[str]:
    sentences = text.replace("\n", " ").replace("\r", " ").split('ã€‚')
    chunks, current_chunk = [], ""
    for sentence in sentences:
        if not sentence.strip(): continue
        sentence += "ã€‚"
        if len(current_chunk) + len(sentence) <= max_chunk_size:
            current_chunk += sentence
        else:
            chunks.append(current_chunk.strip())
            current_chunk = sentence
    if current_chunk: chunks.append(current_chunk.strip())
    return chunks

# --- æ•°æ®åº“ç®¡ç†ç±» ---
class ChatHistoryDB:
    def __init__(self, config: Config):
        self.config = config
        try:
            os.makedirs(config.DB_PATH, exist_ok=True)
            self.db_client = chromadb.PersistentClient(path=self.config.DB_PATH)
            self.embedding_func = embedding_functions.SentenceTransformerEmbeddingFunction(
                model_name=self.config.EMBEDDING_MODEL
            )
            self.chat_collection = self.db_client.get_or_create_collection(name=self.config.CHAT_COLLECTION_NAME, embedding_function=self.embedding_func)
            self.memory_collection = self.db_client.get_or_create_collection(name=self.config.MEMORY_COLLECTION_NAME, embedding_function=self.embedding_func)
            self.rag_collection = self.db_client.get_or_create_collection(name=self.config.RAG_COLLECTION_NAME, embedding_function=self.embedding_func)
            logging.info(f"æ•°æ®åº“åˆå§‹åŒ–æˆåŠŸ: {config.DB_PATH}")
        except Exception as e:
            logging.error(f"åˆå§‹åŒ– ChromaDB å¤±è´¥: {e}")
            st.error(f"æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")
            raise

    # ... å…¶ä»–æ•°æ®åº“æ–¹æ³•ä¿æŒä¸å˜ ...
    def save_message(self, user_id: str, message: dict):
        if not all(k in message for k in ['role', 'content']) or not message.get('content'): return
        timestamp = time.time()
        doc_id = f"msg_{user_id}_{timestamp}"
        self.chat_collection.add(ids=[doc_id], documents=[message['content']], metadatas=[{"user_id": user_id, "role": message['role'], "timestamp": timestamp}])

    def load_history_by_user(self, user_id: str) -> list:
        if not user_id: return []
        results = self.chat_collection.get(where={"user_id": user_id})
        if not results['ids']: return []
        packaged_messages = sorted([{"doc": results['documents'][i], "meta": results['metadatas'][i]} for i in range(len(results['ids']))], key=lambda m: m['meta']['timestamp'])
        return [{"role": msg['meta']['role'], "content": msg['doc']} for msg in packaged_messages]

    def clear_user_chat_history(self, user_id: str):
        if self.chat_collection.get(where={"user_id": user_id})['ids']:
            self.chat_collection.delete(where={"user_id": user_id})
            logging.info(f"å·²æ¸…ç©ºç”¨æˆ· {user_id} çš„å¯¹è¯åŽ†å²ã€‚")
            
    def save_entities_to_memory(self, user_id: str, entities: dict):
        if not entities: return
        for key, value in entities.items():
            doc_id = f"memory_{user_id}_{key}"
            self.memory_collection.upsert(ids=[doc_id], documents=[f"äº‹å®ž: {key} æ˜¯ {value}ã€‚"], metadatas=[{"user_id": user_id, "key": key, "timestamp": time.time()}])

    def load_long_term_memory(self, user_id: str, top_k: int = 20) -> str:
        results = self.memory_collection.get(where={"user_id": user_id}, limit=top_k)
        return "\n".join(results.get('documents', [])) or "æš‚æ— "
        
    def add_document_to_rag(self, user_id: str, file_name: str, file_content: str):
        chunks = simple_text_splitter(file_content)
        if not chunks: return
        doc_ids = [f"rag_{user_id}_{file_name}_{time.time()}_{i}" for i in range(len(chunks))]
        metadatas = [{"user_id": user_id, "source": file_name} for _ in chunks]
        self.rag_collection.add(ids=doc_ids, documents=chunks, metadatas=metadatas)

    def clear_user_rag_documents(self, user_id: str):
        if self.rag_collection.get(where={"user_id": user_id})['ids']:
            self.rag_collection.delete(where={"user_id": user_id})
            logging.info(f"å·²æ¸…ç©ºç”¨æˆ· {user_id} çš„çŸ¥è¯†åº“ã€‚")

    def get_rag_file_list(self, user_id: str) -> list[str]:
        results = self.rag_collection.get(where={"user_id": user_id})
        if not results['ids']: return []
        return sorted(list({meta['source'] for meta in results['metadatas'] if 'source' in meta}))

    # â­ V2.6 æ ¸å¿ƒä¼˜åŒ–: ä¸ºRAGæ£€ç´¢å‡½æ•°å¢žåŠ ç¼“å­˜
    # è¿™å°†ç¼“å­˜ç›¸åŒç”¨æˆ·å¯¹ç›¸åŒæŸ¥è¯¢çš„æ£€ç´¢ç»“æžœï¼Œé¿å…é‡å¤è®¡ç®—
    @st.cache_data(show_spinner=False)
    def query_rag_documents(_self, user_id: str, query: str, top_k: int = 3) -> str:
        """ä»Žç”¨æˆ·ä¸“å±žçš„RAGçŸ¥è¯†åº“ä¸­æ£€ç´¢ä¿¡æ¯ (å¸¦ç¼“å­˜)"""
        logging.info(f"æ­£åœ¨ä¸ºç”¨æˆ· {user_id} æ‰§è¡ŒRAGæ£€ç´¢ï¼ŒæŸ¥è¯¢: '{query}'")
        if not _self.rag_collection.get(where={"user_id": user_id}, limit=1)['ids']:
            return ""

        results = _self.rag_collection.query(query_texts=[query], where={"user_id": user_id}, n_results=top_k)
        retrieved_docs = results.get("documents", [[]])[0]
        if not retrieved_docs: return ""
        
        formatted_docs = "\n".join([f"- {doc}" for doc in retrieved_docs])
        return f"ä»Žä½ çš„çŸ¥è¯†åº“ä¸­æ‰¾åˆ°ä»¥ä¸‹ç›¸å…³ä¿¡æ¯ï¼š\n{formatted_docs}"
        
    @st.cache_data(show_spinner=False)
    def query_recent_discussions(_self, user_id: str, query: str, top_k: int = 3) -> str:
        """ä»ŽåŽ†å²å¯¹è¯ä¸­æ£€ç´¢ä¿¡æ¯ (å¸¦ç¼“å­˜)"""
        logging.info(f"æ­£åœ¨ä¸ºç”¨æˆ· {user_id} æ‰§è¡ŒåŽ†å²å¯¹è¯æ£€ç´¢ï¼ŒæŸ¥è¯¢: '{query}'")
        if not _self.chat_collection.get(where={"user_id": user_id}, limit=1)['ids']:
            return "è¯¥ç”¨æˆ·æ²¡æœ‰ä»»ä½•åŽ†å²å¯¹è¯è®°å½•ã€‚"
        results = _self.chat_collection.query(query_texts=[query], where={"user_id": user_id}, n_results=top_k)
        retrieved_docs = results.get("documents", [[]])[0]
        if not retrieved_docs: return "åœ¨ä½ çš„åŽ†å²è®°å½•ä¸­ï¼Œæ²¡æœ‰æ‰¾åˆ°ä¸Žå½“å‰é—®é¢˜ç›¸å…³çš„å†…å®¹ã€‚"
        formatted_docs = "\n".join([f"- \"{doc}\"" for doc in retrieved_docs])
        return f"ä½ å›žå¿†èµ·äº†ä»¥ä¸‹å¯èƒ½ç›¸å…³çš„åŽ†å²å¯¹è¯å†…å®¹ï¼š\n{formatted_docs}"


# --- æ™ºèƒ½ä»£ç†ç±» ---
class ChatAgent:
    def __init__(self, config: Config, db_manager: ChatHistoryDB, api_key: str, user_id: str):
        self.config, self.db_manager, self.api_key, self.user_id = config, db_manager, api_key, user_id
        if not api_key: raise ValueError("å¿…é¡»æä¾› ZHIPU_API_KEYã€‚")
        self.client = OpenAI(api_key=api_key, base_url=self.config.ZHIPU_BASE_URL)
        self.refresh_agent_state()

    def refresh_agent_state(self):
        long_term_memory = self.db_manager.load_long_term_memory(self.user_id)
        system_prompt = self.config.SYSTEM_PROMPT_TEMPLATE.format(user_id=self.user_id, long_term_memory=long_term_memory)
        self.messages = self.db_manager.load_history_by_user(self.user_id)
        if not self.messages or self.messages[0]['role'] != 'system':
            self.messages.insert(0, {"role": "system", "content": system_prompt})
        else: self.messages[0] = {"role": "system", "content": system_prompt}

    def run(self, user_input: str):
        # ä½¿ç”¨ç¼“å­˜çš„æ£€ç´¢å‡½æ•°
        context_from_rag = self.db_manager.query_rag_documents(self.user_id, user_input)
        context_from_history = self.db_manager.query_recent_discussions(self.user_id, user_input)
        
        messages_for_llm = list(self.messages)
        if context_from_rag: messages_for_llm.append({"role": "system", "content": context_from_rag})
        if context_from_history: messages_for_llm.append({"role": "system", "content": context_from_history})
        messages_for_llm.append({"role": "user", "content": user_input})
        
        try:
            response = self.client.chat.completions.create(model=self.config.LLM_MODEL, messages=messages_for_llm)
            final_response = response.choices[0].message.content or "æŠ±æ­‰ï¼Œæˆ‘ä¸çŸ¥é“å¦‚ä½•å›žå¤ã€‚"
        except Exception as e:
            logging.error(f"è°ƒç”¨LLM APIå¤±è´¥: {e}")
            final_response = f"æŠ±æ­‰ï¼Œå‡ºé”™äº†: {e}"
            
        user_message = {"role": "user", "content": user_input}
        assistant_message = {"role": "assistant", "content": final_response}
        self.db_manager.save_message(self.user_id, user_message)
        self.db_manager.save_message(self.user_id, assistant_message)
        self.messages.extend([user_message, assistant_message])
        
        user_message_count = sum(1 for msg in self.messages if msg['role'] == 'user')
        if user_message_count > 0 and user_message_count % self.config.MEMORY_EXTRACTION_INTERVAL == 0:
            self.extract_and_save_memory(is_periodic=True)
        return final_response

    def extract_and_save_memory(self, is_periodic=False):
        conversation = [msg for msg in self.messages if msg['role'] in ['user', 'assistant']]
        if len(conversation) < 2: return False
        full_chat_content = "\n".join([f"{m['role']}: {m['content']}" for m in conversation])
        memory_prompt = f"""è¯·ä»”ç»†é˜…è¯»ç”¨æˆ· {self.user_id} çš„å¯¹è¯ï¼Œå¹¶ä»¥JSONæ ¼å¼ï¼Œæç‚¼å‡ºæ ¸å¿ƒäº‹å®žå’Œé•¿æœŸåå¥½ã€‚å¦‚æžœæ²¡æœ‰ï¼Œè¿”å›ž{{}}ã€‚\nå¯¹è¯å†…å®¹:\n---\n{full_chat_content}\n---\næå–çš„JSON:"""
        try:
            response = self.client.chat.completions.create(model=self.config.LLM_MODEL, messages=[{"role": "user", "content": memory_prompt}], response_format={"type": "json_object"})
            content = response.choices[0].message.content
            if content and (extracted_data := json.loads(content)):
                self.db_manager.save_entities_to_memory(self.user_id, extracted_data)
                self.refresh_agent_state()
                return True
            return False
        except Exception as e:
            logging.error(f"è§£æžæˆ–ä¿å­˜é•¿æœŸè®°å¿†å¤±è´¥: {e}")
            return False

# -----------------------------------------------------------------------------
# æ­¥éª¤ 3: Streamlit å‰ç«¯ç•Œé¢ (V2.6 - å‰ç«¯é€»è¾‘æ— å˜åŒ–)
# -----------------------------------------------------------------------------

st.set_page_config(page_title="æ‚¨çš„ä¸“å±žè®°å¿†åŠ©ç† V2.6", page_icon="ðŸ§ ", layout="centered")

@st.cache_resource
def get_core_services():
    config = Config()
    db_manager = ChatHistoryDB(config)
    return config, db_manager

config, db_manager = get_core_services()
api_key = os.getenv("ZHIPUAI_API_KEY")
if not api_key:
    st.error("æœªæ‰¾åˆ° ZHIPUAI_API_KEY çŽ¯å¢ƒå˜é‡ï¼Œè¯·é…ç½®ã€‚")
    st.stop()
    
if "logged_in_user_id" not in st.session_state: st.session_state.logged_in_user_id = None
if "agent" not in st.session_state: st.session_state.agent = None

# --- ä¾§è¾¹æ  ---
with st.sidebar:
    st.header("ðŸ‘¤ ç”¨æˆ·ä¸­å¿ƒ")
    user_id_input = st.text_input("è¯·è¾“å…¥æ‚¨çš„ç”¨æˆ·ID", key="user_id_input", placeholder="ä¾‹å¦‚: zhangsan")
    if st.button("ç™»å½• / åˆ‡æ¢ç”¨æˆ·", key="login_button"):
        if user_id_input:
            if st.session_state.agent and st.session_state.logged_in_user_id != user_id_input:
                with st.spinner("æ²‰æ·€æœ€ç»ˆè®°å¿†..."): st.session_state.agent.extract_and_save_memory()
            st.session_state.logged_in_user_id = user_id_input
            st.session_state.agent = None
            st.toast(f"æ¬¢è¿Žå›žæ¥, {user_id_input}ï¼", icon="âœ…")
            st.rerun()
        else: st.warning("è¯·è¾“å…¥ä¸€ä¸ªç”¨æˆ·IDã€‚")

    if st.session_state.logged_in_user_id:
        current_user_id = st.session_state.logged_in_user_id
        st.markdown("---")
        st.header("ðŸ“š çŸ¥è¯†åº“ (RAG)")
        uploaded_file = st.file_uploader("ä¸Šä¼ çŸ¥è¯†æ–‡ä»¶ (.txt/.md)", type=['txt', 'md'], key=f"uploader_{current_user_id}")
        if uploaded_file:
            with st.spinner(f"å­¦ä¹ æ–‡ä»¶: {uploaded_file.name}..."):
                try:
                    content = uploaded_file.getvalue().decode("utf-8")
                    db_manager.add_document_to_rag(current_user_id, uploaded_file.name, content)
                    st.toast(f"æ–‡ä»¶ '{uploaded_file.name}' å·²æ·»åŠ ï¼", icon="âœ…")
                    st.rerun()
                except Exception as e: st.error(f"å¤„ç†æ–‡ä»¶å¤±è´¥: {e}")
        
        rag_files = db_manager.get_rag_file_list(current_user_id)
        if rag_files:
            with st.expander("æŸ¥çœ‹å·²ä¸Šä¼ çš„æ–‡ä»¶", expanded=True):
                for f in rag_files: st.caption(f)
            if st.button("ðŸ—‘ï¸ æ¸…ç©ºæ‰€æœ‰çŸ¥è¯†åº“æ–‡ä»¶", key="clear_rag"):
                with st.spinner("æ¸…ç©ºçŸ¥è¯†åº“..."):
                    db_manager.clear_user_rag_documents(current_user_id)
                    st.cache_data.clear() # æ¸…ç©ºæ‰€æœ‰ç¼“å­˜
                st.toast("çŸ¥è¯†åº“å·²æ¸…ç©ºï¼", icon="ðŸ—‘ï¸")
                st.rerun()

        st.markdown("---")
        st.header("ðŸ› ï¸ è®°å¿†å·¥å…·ç®±")
        if st.button("ðŸ§  ä¸»åŠ¨æç‚¼è®°å¿†", key="extract_memory"):
            if st.session_state.agent:
                with st.spinner("åˆ†æžå’Œæ²‰æ·€è®°å¿†..."): saved = st.session_state.agent.extract_and_save_memory()
                st.toast("è®°å¿†å·²æ›´æ–°ï¼" if saved else "æœªå‘çŽ°æ–°çš„å¯è®°å¿†ä¿¡æ¯ã€‚", icon="ï¿½")
                st.rerun()
        if st.button("ðŸ§¹ æ¸…ç†å½“å‰å¯¹è¯", key="clear_chat"):
            if st.session_state.agent:
                with st.spinner("ä¿å­˜æœ€åŽçš„å›žå¿†..."): st.session_state.agent.extract_and_save_memory()
                with st.spinner("æ¸…ç©ºå¯¹è¯åŽ†å²..."):
                    db_manager.clear_user_chat_history(current_user_id)
                    st.cache_data.clear() # æ¸…ç©ºæ‰€æœ‰ç¼“å­˜
                st.session_state.agent = None
                st.toast("å¯¹è¯åŽ†å²å·²æ¸…ç©ºï¼", icon="ðŸ—‘ï¸")
                st.rerun()
        with st.expander("ðŸ‘€ æŸ¥çœ‹æˆ‘çš„é•¿æœŸè®°å¿†"):
            memory_content = db_manager.load_long_term_memory(current_user_id)
            st.code(memory_content, language=None) if memory_content.strip() and memory_content != "æš‚æ— " else st.info("æš‚æ— é•¿æœŸè®°å¿†ã€‚")
    else: st.caption("è¯·å…ˆç™»å½•ä»¥ä½¿ç”¨å…¨éƒ¨åŠŸèƒ½ã€‚")

# --- ä¸»èŠå¤©ç•Œé¢ ---
st.title("ðŸ§  æ‚¨çš„ä¸“å±žè®°å¿†åŠ©ç† V2.6")
if not st.session_state.logged_in_user_id:
    st.info("ðŸ‘ˆ è¯·åœ¨å·¦ä¾§è¾¹æ è¾“å…¥ç”¨æˆ·IDå¹¶ç™»å½•ã€‚")
    st.stop()
try:
    if st.session_state.agent is None:
        st.session_state.agent = ChatAgent(config, db_manager, api_key, st.session_state.logged_in_user_id)
except Exception as e:
    st.error(f"åˆå§‹åŒ–åŠ©ç†å‡ºé”™: {e}")
    st.stop()
for message in st.session_state.agent.messages:
    if message["role"] in ["user", "assistant"]:
        with st.chat_message(message["role"]): st.markdown(message["content"])
if prompt := st.chat_input(f"æ‚¨å¥½, {st.session_state.logged_in_user_id}, æœ‰ä½•è´µå¹²?"):
    st.chat_message("user").markdown(prompt)
    with st.spinner("æ€è€ƒä¸­..."):
        response = st.session_state.agent.run(prompt)
    with st.chat_message("assistant"):
        st.markdown(response)
    st.rerun()
